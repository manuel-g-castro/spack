From 9de39a40b931771aed7c36ef54eeb13db69b7279 Mon Sep 17 00:00:00 2001
From: Gilles Gouaillardet <gilles@rist.or.jp>
Date: Mon, 12 Aug 2019 14:57:09 +0900
Subject: [PATCH 04/32] simd: add support for ARMv8+sve support (ARM_SVE)

SVE support is added to GROMACS by running cmake -DGMX_SIMD=ARM_SVE ...
It is important to note the vector length (VL) is fixed at cmake time.
The default VL is 512 bits and it can be changed via the
GMX_SIMD_ARM_SVE_LENGTH macro.

SVE support for GROMACS is contributed by the Research Organization
for Science Information and Technology (RIST).

(cherry picked from commit 9f7a4905ca3a2be3013b871925b910e6d6783b43)
---
 CMakeLists.txt                                     |   3 +-
 cmake/gmxDetectSimd.cmake                          |   2 +
 cmake/gmxManageSimd.cmake                          |  42 ++
 src/config.h.cmakein                               |   6 +
 src/gromacs/hardware/cpuinfo.cpp                   |  14 +-
 src/gromacs/hardware/cpuinfo.h                     |   3 +-
 src/gromacs/simd/impl_arm_sve/impl_arm_sve.h       |  60 ++
 .../simd/impl_arm_sve/impl_arm_sve_definitions.h   | 137 ++++
 .../simd/impl_arm_sve/impl_arm_sve_general.h       |  57 ++
 .../simd/impl_arm_sve/impl_arm_sve_simd4_double.h  | 355 ++++++++++
 .../simd/impl_arm_sve/impl_arm_sve_simd4_float.h   | 662 ++++++++++++++++++
 .../simd/impl_arm_sve/impl_arm_sve_simd_double.h   | 746 ++++++++++++++++++++
 .../simd/impl_arm_sve/impl_arm_sve_simd_float.h    | 752 +++++++++++++++++++++
 .../simd/impl_arm_sve/impl_arm_sve_util_double.h   | 381 +++++++++++
 .../simd/impl_arm_sve/impl_arm_sve_util_float.h    | 611 +++++++++++++++++
 src/gromacs/simd/simd.h                            |   2 +
 src/gromacs/simd/support.cpp                       |  55 +-
 src/gromacs/simd/support.h                         |   3 +-
 18 files changed, 3883 insertions(+), 8 deletions(-)
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve.h
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve_definitions.h
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve_general.h
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd4_double.h
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd4_float.h
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd_double.h
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd_float.h
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve_util_double.h
 create mode 100644 src/gromacs/simd/impl_arm_sve/impl_arm_sve_util_float.h

diff --git a/CMakeLists.txt b/CMakeLists.txt
index 34f6550..3d72799 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -232,7 +232,7 @@ gmx_option_multichoice(
     GMX_SIMD
     "SIMD instruction set for CPU kernels and compiler optimization"
     "AUTO"
-    AUTO None SSE2 SSE4.1 AVX_128_FMA AVX_256 AVX2_256 AVX2_128 AVX_512 AVX_512_KNL MIC ARM_NEON ARM_NEON_ASIMD IBM_VMX IBM_VSX Sparc64_HPC_ACE Reference)
+    AUTO None SSE2 SSE4.1 AVX_128_FMA AVX_256 AVX2_256 AVX2_128 AVX_512 AVX_512_KNL MIC ARM_NEON ARM_NEON_ASIMD ARM_SVE IBM_VMX IBM_VSX Sparc64_HPC_ACE Reference)
 
 if(GMX_TARGET_MIC)
     set(GMX_FFT_LIBRARY_DEFAULT "mkl")
@@ -266,6 +266,7 @@ gmx_option_multichoice(
 
 gmx_dependent_cache_variable(GMX_SIMD_REF_FLOAT_WIDTH  "Reference SIMD single precision width" STRING "4" "GMX_SIMD STREQUAL REFERENCE")
 gmx_dependent_cache_variable(GMX_SIMD_REF_DOUBLE_WIDTH "Reference SIMD double precision width" STRING "2" "GMX_SIMD STREQUAL REFERENCE")
+gmx_dependent_cache_variable(GMX_SIMD_ARM_SVE_LENGTH "ARM SVE length in bits" STRING "512" "GMX_SIMD STREQUAL ARM_SVE")
 
 # This should be moved to a separate NBNXN cmake module when that code is cleaned up and modularized
 
diff --git a/cmake/gmxDetectSimd.cmake b/cmake/gmxDetectSimd.cmake
index 97d7f5b..2dd8367 100644
--- a/cmake/gmxDetectSimd.cmake
+++ b/cmake/gmxDetectSimd.cmake
@@ -129,6 +129,8 @@ function(gmx_suggest_simd _suggested_simd)
                 set(OUTPUT_SIMD "IBM_VMX")
             elseif(CPU_DETECTION_FEATURES MATCHES " neon_asimd ")
                 set(OUTPUT_SIMD "ARM_NEON_ASIMD")
+            elseif(CPU_DETECTION_FEATURES MATCHES " sve ")
+                set(OUTPUT_SIMD "ARM_SVE")
             elseif(CPU_DETECTION_FEATURES MATCHES " neon " AND NOT GMX_DOUBLE)
                 set(OUTPUT_SIMD "ARM_NEON")
             endif()
diff --git a/cmake/gmxManageSimd.cmake b/cmake/gmxManageSimd.cmake
index cd507c1..cacb557 100644
--- a/cmake/gmxManageSimd.cmake
+++ b/cmake/gmxManageSimd.cmake
@@ -247,6 +247,48 @@ elseif(GMX_SIMD_ACTIVE STREQUAL "ARM_NEON_ASIMD")
     set(GMX_SIMD_${GMX_SIMD_ACTIVE} 1)
     set(SIMD_STATUS_MESSAGE "Enabling ARM (AArch64) NEON Advanced SIMD instructions using CXX flags: ${SIMD_ARM_NEON_ASIMD_CXX_FLAGS}")
 
+elseif(GMX_SIMD_ACTIVE STREQUAL "ARM_SVE")
+
+    # Note that GMX_RELAXED_DOUBLE_PRECISION is enabled by default in the top-level CMakeLists.txt
+
+    if(NOT GMX_SIMD_ARM_SVE_LENGTH)
+        set(GMX_SIMD_ARM_SVE_LENGTH 512)
+    endif()
+
+    if(GMX_SIMD_ARM_SVE_LENGTH STREQUAL "scalable")
+        if (GMX_DOUBLE)
+            message(FATAL_ERROR "ARM_SVE SIMD support for scalable vector length is not available for a double precision ")
+        endif()
+        set(GMX_SIMD_ACTIVE "ARM_NEON_ASIMD")
+        gmx_find_simd_arm_neon_asimd_flags(SIMD_ARM_NEON_ASIMD_C_SUPPORTED SIMD_ARM_NEON_ASIMD_CXX_SUPPORTED
+                                           SIMD_ARM_NEON_ASIMD_C_FLAGS SIMD_ARM_NEON_ASIMD_CXX_FLAGS)
+
+        if(NOT SIMD_ARM_NEON_ASIMD_C_SUPPORTED OR NOT SIMD_ARM_NEON_ASIMD_CXX_SUPPORTED)
+            gmx_give_fatal_error_when_simd_support_not_found("ARM (AArch64) NEON Advanced SIMD" "particularly gcc version 4.9 or later, or disable SIMD support (slower)" "${SUGGEST_BINUTILS_UPDATE}")
+        endif()
+
+        # If multiple flags are neeed, make them into a list
+        string(REPLACE " " ";" SIMD_C_FLAGS ${SIMD_ARM_NEON_ASIMD_C_FLAGS})
+        string(REPLACE " " ";" SIMD_CXX_FLAGS ${SIMD_ARM_NEON_ASIMD_CXX_FLAGS})
+        set(GMX_SIMD_${GMX_SIMD_ACTIVE} 1)
+        set(GMX_SIMD_VLA 1)
+        add_definitions(-DGMX_SIMD_VLA=1)
+        set(SIMD_STATUS_MESSAGE "Enabling ARM (AArch64) SVE extensions for scalable vectors SIMD instructions using CXX flags: ${SIMD_ARM_NEON_ASIMD_CXX_FLAGS}")
+    else()
+        add_definitions(-DGMX_SIMD_ARM_SVE_LENGTH=${GMX_SIMD_ARM_SVE_LENGTH})
+
+        if("${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
+            add_definitions(-DGMX_SIMD_ARM_SVE_GNU=1)
+        else()
+            add_definitions(-DGMX_SIMD_ARM_SVE_GNU=0)
+        endif()
+
+        option(GMX_SIMD_ARM_SVE_FULL_LENGTH "Always use full length vectors" OFF)
+
+        set(GMX_SIMD_${GMX_SIMD_ACTIVE} 1)
+        set(SIMD_STATUS_MESSAGE "Enabling ARM (AArch64) SVE extensions without special flags.")
+    endif()
+
 elseif(GMX_SIMD_ACTIVE STREQUAL "IBM_VMX")
 
     gmx_find_simd_ibm_vmx_flags(SIMD_IBM_VMX_C_SUPPORTED SIMD_IBM_VMX_CXX_SUPPORTED
diff --git a/src/config.h.cmakein b/src/config.h.cmakein
index e8ab5c6..a9ee16e 100644
--- a/src/config.h.cmakein
+++ b/src/config.h.cmakein
@@ -108,6 +108,12 @@
 /* ARM (AArch64) NEON Advanced SIMD instruction set level was selected */
 #cmakedefine01 GMX_SIMD_ARM_NEON_ASIMD
 
+/* ARM (SVE) Scalable Vector extensions */
+#cmakedefine01 GMX_SIMD_ARM_SVE
+
+/* ARM (SVE) always use full length vectors */
+#cmakedefine01 GMX_SIMD_ARM_SVE_FULL_LENGTH
+
 /* IBM VMX was selected as SIMD instructions (Power 6 and later) */
 #cmakedefine01 GMX_SIMD_IBM_VMX
 
diff --git a/src/gromacs/hardware/cpuinfo.cpp b/src/gromacs/hardware/cpuinfo.cpp
index 2004d8f..1128f72 100644
--- a/src/gromacs/hardware/cpuinfo.cpp
+++ b/src/gromacs/hardware/cpuinfo.cpp
@@ -2,7 +2,7 @@
  * This file is part of the GROMACS molecular simulation package.
  *
  * Copyright (c) 2012-2018, The GROMACS development team.
- * Copyright (c) 2019, by the GROMACS development team, led by
+ * Copyright (c) 2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -488,8 +488,9 @@ void renumberIndex(std::vector<unsigned int>* v)
     for (std::size_t i = 0; i < uniqueSortedV.size(); i++)
     {
         unsigned int val = uniqueSortedV[i];
-        std::replace_if(v->begin(), v->end(), [val](unsigned int& c) -> bool { return c == val; },
-                        static_cast<unsigned int>(i));
+        std::replace_if(
+                v->begin(), v->end(), [val](unsigned int& c) -> bool { return c == val; },
+                static_cast<unsigned int>(i));
     }
 }
 
@@ -887,6 +888,9 @@ void detectProcCpuInfoArm(const std::map<std::string, std::string>& cpuInfo,
                 features->insert(CpuInfo::Feature::Arm_NeonAsimd);
             }
         }
+#if GMX_SIMD_ARM_SVE
+        features->insert(CpuInfo::Feature::Arm_Sve);
+#endif
     }
 }
 
@@ -983,6 +987,9 @@ CpuInfo CpuInfo::detect()
         result.features_.insert(Feature::Arm_Neon);      // ARMv8 always has Neon
         result.features_.insert(Feature::Arm_NeonAsimd); // ARMv8 always has Neon-asimd
 #endif
+#if GMX_SIMD_ARM_SVE
+        result.features_.insert(Feature::Arm_Sve); /* GG FIXME */
+#endif
 
 #if defined sun
         result.vendor_ = CpuInfo::Vendor::Oracle;
@@ -1086,6 +1093,7 @@ const std::string& CpuInfo::featureString(Feature f)
         { Feature::X86_Xop, "xop" },
         { Feature::Arm_Neon, "neon" },
         { Feature::Arm_NeonAsimd, "neon_asimd" },
+        { Feature::Arm_Sve, "sve" },
         { Feature::Ibm_Qpx, "qpx" },
         { Feature::Ibm_Vmx, "vmx" },
         { Feature::Ibm_Vsx, "vsx" },
diff --git a/src/gromacs/hardware/cpuinfo.h b/src/gromacs/hardware/cpuinfo.h
index b2e3058..adeb1f7 100644
--- a/src/gromacs/hardware/cpuinfo.h
+++ b/src/gromacs/hardware/cpuinfo.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2015,2016,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2015,2016,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -144,6 +144,7 @@ public:
         X86_Xop,         //!< AMD extended instructions, only AMD for now
         Arm_Neon,        //!< 32-bit ARM NEON
         Arm_NeonAsimd,   //!< 64-bit ARM AArch64 Advanced SIMD
+        Arm_Sve,         //!< ARM Scalable Vector Extensions
         Ibm_Qpx,         //!< IBM QPX SIMD (BlueGene/Q)
         Ibm_Vmx,         //!< IBM VMX SIMD (Altivec on Power6 and later)
         Ibm_Vsx,         //!< IBM VSX SIMD (Power7 and later)
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve.h
new file mode 100644
index 0000000..36bc43d
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve.h
@@ -0,0 +1,60 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_H
+#define GMX_SIMD_IMPL_ARM_SVE_H
+
+#if GMX_SIMD_ARM_SVE_GNU
+#    define GMX_SIMD_ARM_SVE_STRUCT struct
+#else
+#    define GMX_SIMD_ARM_SVE_STRUCT __sizeless_struct
+#endif
+
+#include "impl_arm_sve_definitions.h"
+#include "impl_arm_sve_general.h"
+#include "impl_arm_sve_simd4_float.h"
+#include "impl_arm_sve_simd4_double.h"
+#include "impl_arm_sve_simd_float.h"
+#include "impl_arm_sve_simd_double.h"
+#include "impl_arm_sve_util_float.h"
+#include "impl_arm_sve_util_double.h"
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_H
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve_definitions.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_definitions.h
new file mode 100644
index 0000000..c631c50
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_definitions.h
@@ -0,0 +1,137 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_DEFINITIONS_H
+#define GMX_SIMD_IMPL_ARM_SVE_DEFINITIONS_H
+
+#define GMX_SIMD 1
+#define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_LOADU 1
+#define GMX_SIMD_HAVE_STOREU 1
+#define GMX_SIMD_HAVE_LOGICAL 1
+#define GMX_SIMD_HAVE_FMA 1
+#define GMX_SIMD_HAVE_FINT32_EXTRACT 1
+#define GMX_SIMD_HAVE_FINT32_LOGICAL 1
+#define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_EXTRACT 1
+#define GMX_SIMD_HAVE_DINT32_LOGICAL 1
+#define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
+#define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT \
+    0 // Although there is support, it is disabled in GROMACS, because rsqrtIter does not work correctly for inputs near MAX_FLOAT
+#define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 1
+#define GMX_SIMD_HAVE_NATIVE_LOG_FLOAT 0
+#define GMX_SIMD_HAVE_NATIVE_EXP2_FLOAT 0
+#define GMX_SIMD_HAVE_NATIVE_EXP_FLOAT 0
+#define GMX_SIMD_HAVE_NATIVE_COPYSIGN_DOUBLE 0
+#define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_DOUBLE 0
+#define GMX_SIMD_HAVE_NATIVE_RCP_ITER_DOUBLE 1
+#define GMX_SIMD_HAVE_NATIVE_LOG_DOUBLE 0
+#define GMX_SIMD_HAVE_NATIVE_EXP2_DOUBLE 0
+#define GMX_SIMD_HAVE_NATIVE_EXP_DOUBLE 0
+#define GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_FLOAT 1
+#define GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_DOUBLE 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_FLOAT 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_LOADDUPLICATE2_FLOAT 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_LOADDUPLICATE3_FLOAT 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_DECR3_FLOAT 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_LOADU12DUAL_FLOAT 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_LOADU14DUAL_FLOAT 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_REDUCEINCR4_FLOAT 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_GATHER_LOAD_TRANSPOSE2_FLOAT 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 1
+#define GMX_SIMD_HAVE_HSIMD_UTIL_LOADDUPLICATE2_DOUBLE 0
+#define GMX_SIMD_HAVE_HSIMD_UTIL_LOADDUPLICATE3_DOUBLE 0
+#define GMX_SIMD_HAVE_HSIMD_UTIL_DECR3_DOUBLE 0
+#define GMX_SIMD_HAVE_HSIMD_UTIL_LOADU12DUAL_DOUBLE 0
+#define GMX_SIMD_HAVE_HSIMD_UTIL_LOADU14DUAL_DOUBLE 0
+#define GMX_SIMD_HAVE_HSIMD_UTIL_REDUCEINCR4_DOUBLE 0
+#define GMX_SIMD_HAVE_HSIMD_UTIL_GATHER_LOAD_TRANSPOSE2_DOUBLE 0
+#if GMX_SIMD_ARM_SVE_LENGTH > 128
+#    define GMX_SIMD_HAVE_4NSIMD_UTIL_FLOAT 0
+#endif
+#if GMX_SIMD_ARM_SVE_LENGTH > 256
+#    define GMX_SIMD_HAVE_4NSIMD_UTIL_DOUBLE 0
+#endif
+
+#define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
+#define GMX_SIMD4_HAVE_DOUBLE 1
+
+#if GMX_SIMD_ARM_SVE_GNU
+#    define GMX_SIMD_ALIGNMENT 16
+#endif
+
+#if GMX_SIMD_ARM_SVE_GNU
+#    define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#    define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
+#    define GMX_SIMD_HAVE_FINT32_GLOBAL 1
+#    define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#    define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
+#    define GMX_SIMD_HAVE_DINT32_GLOBAL 1
+#    define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+#    define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
+#else
+#    define GMX_SIMD_HAVE_FLOAT_ARRAY 0
+#    define GMX_SIMD_HAVE_FLOAT_GLOBAL 0
+#    define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
+#    define GMX_SIMD_HAVE_DOUBLE_GLOBAL 0
+#    define GMX_SIMD_HAVE_FINT32_GLOBAL 0
+#    define GMX_SIMD_HAVE_DINT32_GLOBAL 0
+#    define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+#    define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 0
+#endif
+
+// Implementation details
+#define GMX_SIMD_FLOAT_WIDTH (GMX_SIMD_ARM_SVE_LENGTH / 32)
+#define GMX_SIMD_DOUBLE_WIDTH (GMX_SIMD_ARM_SVE_LENGTH / 64)
+#if !GMX_SIMD_ARM_SVE_GNU
+#    define GMX_SIMD_ALIGNMENT (GMX_SIMD_ARM_SVE_LENGTH / 8) // Bytes
+#endif
+#define GMX_SIMD_FINT32_WIDTH GMX_SIMD_FLOAT_WIDTH
+#define GMX_SIMD_DINT32_WIDTH GMX_SIMD_DOUBLE_WIDTH
+#define GMX_SIMD4_WIDTH 4
+#define GMX_SIMD_RSQRT_BITS 8
+#define GMX_SIMD_RCP_BITS 8
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_DEFINITIONS_H
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve_general.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_general.h
new file mode 100644
index 0000000..147155c
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_general.h
@@ -0,0 +1,57 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2014,2015,2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_GENERAL_H
+#define GMX_SIMD_IMPL_ARM_SVE_GENERAL_H
+
+namespace gmx
+{
+
+static inline void simdPrefetch(void* m)
+{
+#ifdef __GNUC__
+    __builtin_prefetch(m);
+#endif
+}
+
+} // namespace gmx
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_GENERAL_H
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd4_double.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd4_double.h
new file mode 100644
index 0000000..08611f9
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd4_double.h
@@ -0,0 +1,355 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_SIMD4_DOUBLE_H
+#define GMX_SIMD_IMPL_ARM_SVE_SIMD4_DOUBLE_H
+
+#include "config.h"
+
+#include <cassert>
+#include <cstddef>
+#include <cstdint>
+
+#include <arm_sve.h>
+
+#include "gromacs/math/utilities.h"
+
+namespace gmx
+{
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct Simd4Double
+#else
+typedef __sizeless_struct Simd4Double
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    float64_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+#else
+    svfloat64_t simdInternal_;
+#endif
+
+    Simd4Double(const double d) { this->simdInternal_ = svdup_f64(d); }
+
+    Simd4Double(svfloat64_t simd) : simdInternal_(simd) {}
+
+    Simd4Double() {}
+} Simd4Double;
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct Simd4DBool
+#else
+typedef __sizeless_struct Simd4DBool
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    uint64_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+
+    Simd4DBool(const bool b) { this->simdInternal_ = svdup_n_u64_z(svptrue_b64(), b ? 1 : 0); }
+
+    Simd4DBool(svbool_t simd) { this->simdInternal_ = svdup_n_u64_z(simd, 1); }
+#else
+    svbool_t simdInternal_;
+
+    Simd4DBool(const bool b)
+    {
+        if (b)
+        {
+            this->simdInternal_ = svptrue_b64();
+        }
+        else
+        {
+            this->simdInternal_ = svpfalse_b();
+        }
+    }
+
+    Simd4DBool(svbool_t simd) : simdInternal_(simd) {}
+#endif
+
+    Simd4DBool() {}
+} Simd4DBool;
+
+#if GMX_SIMD_ARM_SVE_GNU
+static inline svbool_t getMask(Simd4DBool m)
+{
+    return svcmpne_n_u64(svptrue_b64(), m.simdInternal_, 0);
+}
+#else
+#    define getMask(m) (m).simdInternal_
+#endif
+
+static inline Simd4Double gmx_simdcall load4(const double* m)
+{
+    assert(std::size_t(m) % 32 == 0);
+    svbool_t pg = svwhilelt_b64(0, 4);
+    return { svld1_f64(pg, m) };
+}
+
+static inline void gmx_simdcall store4(double* m, Simd4Double a)
+{
+    assert(std::size_t(m) % 32 == 0);
+    svbool_t pg = svwhilelt_b64(0, 4);
+    svst1_f64(pg, m, a.simdInternal_);
+}
+
+static inline Simd4Double gmx_simdcall load4U(const double* m)
+{
+    svbool_t pg = svwhilelt_b64(0, 4);
+    return { svld1_f64(pg, m) };
+}
+
+static inline void gmx_simdcall store4U(double* m, Simd4Double a)
+{
+    svbool_t pg = svwhilelt_b64(0, 4);
+    svst1_f64(pg, m, a.simdInternal_);
+}
+
+static inline Simd4Double gmx_simdcall simd4SetZeroD()
+{
+    return { svdup_f64(0.0f) };
+}
+
+static inline Simd4Double gmx_simdcall operator&(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svreinterpret_f64_s64(svand_s64_z(pg, svreinterpret_s64_f64(a.simdInternal_),
+                                               svreinterpret_s64_f64(b.simdInternal_))) };
+}
+
+static inline Simd4Double gmx_simdcall andNot(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svreinterpret_f64_s64(svbic_s64_z(pg, svreinterpret_s64_f64(b.simdInternal_),
+                                               svreinterpret_s64_f64(a.simdInternal_))) };
+}
+
+static inline Simd4Double gmx_simdcall operator|(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svreinterpret_f64_s64(svorr_s64_z(pg, svreinterpret_s64_f64(a.simdInternal_),
+                                               svreinterpret_s64_f64(b.simdInternal_))) };
+}
+
+static inline Simd4Double gmx_simdcall operator^(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svreinterpret_f64_s64(sveor_s64_z(pg, svreinterpret_s64_f64(a.simdInternal_),
+                                               svreinterpret_s64_f64(b.simdInternal_))) };
+}
+
+static inline Simd4Double gmx_simdcall operator+(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svadd_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall operator-(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svsub_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall operator-(Simd4Double a)
+{
+    svbool_t pg = svptrue_b64();
+    return { svneg_f64_z(pg, a.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall operator*(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmul_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall fma(Simd4Double a, Simd4Double b, Simd4Double c)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmad_f64_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall fms(Simd4Double a, Simd4Double b, Simd4Double c)
+{
+    svbool_t pg = svptrue_b64();
+    return { svnmsb_f64_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall fnma(Simd4Double a, Simd4Double b, Simd4Double c)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmsb_f64_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall fnms(Simd4Double a, Simd4Double b, Simd4Double c)
+{
+    svbool_t pg = svptrue_b64();
+    return { svnmad_f64_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall rsqrt(Simd4Double x)
+{
+    svbool_t    pg = svwhilelt_b64(0, 4);
+    svfloat64_t f  = svsplice_f64(pg, x.simdInternal_, svdup_n_f64(1.0f));
+    return { svrsqrte_f64(f) };
+}
+
+static inline Simd4Double gmx_simdcall abs(Simd4Double x)
+{
+    svbool_t pg = svptrue_b64();
+    return { svabs_f64_z(pg, x.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall max(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmax_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall min(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmin_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+// Round and trunc operations are defined at the end of this file, since they
+// need to use float-to-integer and integer-to-float conversions.
+
+static inline double gmx_simdcall reduce(Simd4Double a)
+{
+    svbool_t pg = svwhilelt_b64(0, 4);
+    return svadda_f64(pg, 0.0f, a.simdInternal_);
+}
+
+static inline Simd4DBool gmx_simdcall operator==(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmpeq_f64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4DBool gmx_simdcall operator!=(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmpne_f64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4DBool gmx_simdcall operator<(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmplt_f64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4DBool gmx_simdcall operator<=(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmple_f64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4DBool gmx_simdcall operator&&(Simd4DBool a, Simd4DBool b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svand_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline Simd4DBool gmx_simdcall operator||(Simd4DBool a, Simd4DBool b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svorr_b_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline bool gmx_simdcall anyTrue(Simd4DBool a)
+{
+    svbool_t pg = svwhilelt_b64(0, 4);
+    return svptest_any(pg, getMask(a));
+}
+
+static inline Simd4Double gmx_simdcall selectByMask(Simd4Double a, Simd4DBool m)
+{
+    return { svsel_f64(getMask(m), a.simdInternal_, svdup_f64(0.0f)) };
+}
+
+static inline Simd4Double gmx_simdcall selectByNotMask(Simd4Double a, Simd4DBool m)
+{
+    svbool_t pg = svptrue_b64();
+    return { svsel_f64(sveor_b_z(pg, getMask(m), pg), a.simdInternal_, svdup_f64(0.0f)) };
+}
+
+static inline Simd4Double gmx_simdcall blend(Simd4Double a, Simd4Double b, Simd4DBool sel)
+{
+    return { svsel_f64(getMask(sel), b.simdInternal_, a.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall round(Simd4Double x)
+{
+    svbool_t pg = svptrue_b64();
+    return { svrinta_f64_z(pg, x.simdInternal_) };
+}
+
+static inline Simd4Double gmx_simdcall trunc(Simd4Double x)
+{
+    svbool_t pg = svwhilelt_b64(0, 4);
+    return { svcvt_f64_z(pg, svcvt_s64_z(pg, x.simdInternal_)) };
+}
+
+static inline double gmx_simdcall dotProduct(Simd4Double a, Simd4Double b)
+{
+    svbool_t pg = svwhilelt_b64(0, 3);
+    return svadda_f64(pg, 0.0f, svmul_f64_z(pg, a.simdInternal_, b.simdInternal_));
+}
+
+static inline void gmx_simdcall transpose(Simd4Double* v0, Simd4Double* v1, Simd4Double* v2, Simd4Double* v3)
+{
+    svbool_t pg = svwhilelt_b64(0, 4);
+    double   tmp[16];
+    svst1_f64(pg, tmp, v0->simdInternal_);
+    svst1_f64(pg, tmp + 4, v1->simdInternal_);
+    svst1_f64(pg, tmp + 8, v2->simdInternal_);
+    svst1_f64(pg, tmp + 12, v3->simdInternal_);
+
+    svfloat64x4_t vec = svld4_f64(pg, tmp);
+
+    v0->simdInternal_ = svget4_f64(vec, 0);
+    v1->simdInternal_ = svget4_f64(vec, 1);
+    v2->simdInternal_ = svget4_f64(vec, 2);
+    v3->simdInternal_ = svget4_f64(vec, 3);
+}
+
+} // namespace gmx
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_SIMD4_DOUBLE_H
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd4_float.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd4_float.h
new file mode 100644
index 0000000..d8fc056
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd4_float.h
@@ -0,0 +1,662 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_SIMD4_FLOAT_H
+#define GMX_SIMD_IMPL_ARM_SVE_SIMD4_FLOAT_H
+
+#include "config.h"
+
+#include <cassert>
+#include <cstddef>
+#include <cstdint>
+
+#if 0
+#    include <arm_sve.h>
+#else
+#    include <arm_neon.h>
+#endif
+
+#include "gromacs/math/utilities.h"
+
+namespace gmx
+{
+
+#if 0
+typedef GMX_SIMD_ARM_SVE_STRUCT Simd4Float {
+    svfloat32_t simdInternal_;
+
+    Simd4Float(const float f) {
+        this->simdInternal_ = svdup_f32(f);
+    }
+
+    Simd4Float(svfloat32_t simd) : simdInternal_(simd) {}
+
+    Simd4Float() {
+    }
+} Simd4Float;
+
+typedef GMX_SIMD_ARM_SVE_STRUCT Simd4FBool {
+    svbool_t simdInternal_;
+
+    Simd4FBool(const bool b) {
+        // this->simdInternal_ = svdup_b32(b);
+        if (b) {
+            this->simdInternal_ = svptrue_b32();
+        } else {
+            this->simdInternal_ = svpfalse_b();
+        }
+    }
+
+    Simd4FBool(svbool_t simd) : simdInternal_(simd) {}
+
+
+    Simd4FBool() {
+    }
+} Simd4FBool;
+
+static inline Simd4Float gmx_simdcall
+load4(const float *m)
+{
+    assert(std::size_t(m) % 16 == 0);
+    svbool_t pg = svwhilelt_b32(0, 4);
+    return {
+        svld1_f32(pg, m)
+    };
+}
+
+static inline void gmx_simdcall
+store4(float *m, Simd4Float a)
+{
+    assert(std::size_t(m) % 16 == 0);
+    svbool_t pg = svwhilelt_b32(0, 4);
+    svst1_f32(pg, m, a.simdInternal_);
+}
+
+static inline Simd4Float gmx_simdcall
+load4U(const float *m)
+{
+    svbool_t pg = svwhilelt_b32(0, 4);
+    return {
+        svld1_f32(pg, m)
+    };
+}
+
+static inline void gmx_simdcall
+store4U(float *m, Simd4Float a)
+{
+    svbool_t pg = svwhilelt_b32(0, 4);
+    svst1_f32(pg, m, a.simdInternal_);
+}
+
+static inline Simd4Float gmx_simdcall
+simd4SetZeroF()
+{
+    return {
+        svdup_f32(0.0f)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+operator&(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svreinterpret_f32_s32(svand_s32_z(pg, svreinterpret_s32_f32(a.simdInternal_),
+                                              svreinterpret_s32_f32(b.simdInternal_)))
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+andNot(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svreinterpret_f32_s32(svbic_s32_z(pg, svreinterpret_s32_f32(b.simdInternal_),
+                                              svreinterpret_s32_f32(a.simdInternal_)))
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+operator|(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svreinterpret_f32_s32(svorr_s32_z(pg, svreinterpret_s32_f32(a.simdInternal_),
+                                              svreinterpret_s32_f32(b.simdInternal_)))
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+operator^(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svreinterpret_f32_s32(sveor_s32_z(pg, svreinterpret_s32_f32(a.simdInternal_),
+                                              svreinterpret_s32_f32(b.simdInternal_)))
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+operator+(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svadd_f32_z(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+operator-(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svsub_f32_z(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+operator-(Simd4Float a)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svneg_f32_z(pg, a.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+operator*(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svmul_f32_z(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+fma(Simd4Float a, Simd4Float b, Simd4Float c)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        // svmad_f32_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_)
+        svmla_f32_z(pg, c.simdInternal_, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+fms(Simd4Float a, Simd4Float b, Simd4Float c)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svnmsb_f32_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+fnma(Simd4Float a, Simd4Float b, Simd4Float c)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svmsb_f32_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+fnms(Simd4Float a, Simd4Float b, Simd4Float c)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svnmad_f32_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+rsqrt(Simd4Float x)
+{
+    svbool_t pg = svwhilelt_b32(0, 4);
+    svfloat32_t f = svsplice_f32(pg, x.simdInternal_, svdup_n_f32(1.0f));
+    return {
+        svrsqrte_f32(f)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+abs(Simd4Float x)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svabs_f32_z(pg, x.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+max(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svmax_f32_z(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+min(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svmin_f32_z(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+// Round and trunc operations are defined at the end of this file, since they
+// need to use float-to-integer and integer-to-float conversions.
+
+static inline float gmx_simdcall
+reduce(Simd4Float a)
+{
+    svbool_t pg = svwhilelt_b32(0, 4);
+    return svadda_f32(pg, 0.0f, a.simdInternal_);
+}
+
+static inline Simd4FBool gmx_simdcall
+operator==(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svcmpeq_f32(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4FBool gmx_simdcall
+operator!=(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svcmpne_f32(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4FBool gmx_simdcall
+operator<(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svcmplt_f32(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4FBool gmx_simdcall
+operator<=(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svcmple_f32(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4FBool gmx_simdcall
+operator&&(Simd4FBool a, Simd4FBool b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svand_z(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline Simd4FBool gmx_simdcall
+operator||(Simd4FBool a, Simd4FBool b)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svorr_b_z(pg, a.simdInternal_, b.simdInternal_)
+    };
+}
+
+static inline bool gmx_simdcall
+anyTrue(Simd4FBool a)
+{
+    svbool_t pg = svwhilelt_b32(0, 4);
+    return svptest_any(pg, a.simdInternal_);
+}
+
+static inline Simd4Float gmx_simdcall
+selectByMask(Simd4Float a, Simd4FBool m)
+{
+    return {
+        svsel_f32(m.simdInternal_, a.simdInternal_, svdup_f32(0.0f))
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+selectByNotMask(Simd4Float a, Simd4FBool m)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svsel_f32(sveor_b_z(pg, m.simdInternal_, pg), a.simdInternal_, svdup_f32(0.0f))
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+blend(Simd4Float a, Simd4Float b, Simd4FBool sel)
+{
+    return {
+        svsel_f32(sel.simdInternal_, b.simdInternal_, a.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+round(Simd4Float x)
+{
+    svbool_t pg = svptrue_b32();
+    return {
+        svrinta_f32_z(pg, x.simdInternal_)
+    };
+}
+
+static inline Simd4Float gmx_simdcall
+trunc(Simd4Float x)
+{
+    svbool_t pg = svwhilelt_b32(0, 4);
+    return {
+        svcvt_f32_z(pg, svcvt_s32_z(pg, x.simdInternal_))
+    };
+}
+
+static inline float gmx_simdcall
+dotProduct(Simd4Float a, Simd4Float b)
+{
+    svbool_t pg = svwhilelt_b32(0, 3);
+    return svadda_f32(pg, 0.0f, svmul_f32_z(pg, a.simdInternal_, b.simdInternal_));
+}
+
+static inline void gmx_simdcall
+transpose(Simd4Float * v0, Simd4Float * v1,
+          Simd4Float * v2, Simd4Float * v3)
+{
+    svbool_t pg = svwhilelt_b32(0, 4);
+    float tmp[16];
+    svst1_f32(pg, tmp, v0->simdInternal_);
+    svst1_f32(pg, tmp+4, v1->simdInternal_);
+    svst1_f32(pg, tmp+8, v2->simdInternal_);
+    svst1_f32(pg, tmp+12, v3->simdInternal_);
+        
+    svfloat32x4_t vec = svld4_f32(pg, tmp);
+
+    v0->simdInternal_ = vec.v0;
+    v1->simdInternal_ = vec.v1;
+    v2->simdInternal_ = vec.v2;
+    v3->simdInternal_ = vec.v3;
+}
+
+#else
+
+class Simd4Float
+{
+public:
+    Simd4Float() {}
+
+    Simd4Float(float f) : simdInternal_(vdupq_n_f32(f)) {}
+
+    // Internal utility constructor to simplify return statements
+    Simd4Float(float32x4_t simd) : simdInternal_(simd) {}
+
+    float32x4_t simdInternal_;
+};
+
+class Simd4FBool
+{
+public:
+    Simd4FBool() {}
+
+    Simd4FBool(bool b) : simdInternal_(vdupq_n_u32(b ? 0xFFFFFFFF : 0)) {}
+
+    // Internal utility constructor to simplify return statements
+    Simd4FBool(uint32x4_t simd) : simdInternal_(simd) {}
+
+    uint32x4_t simdInternal_;
+};
+
+static inline Simd4Float gmx_simdcall load4(const float* m)
+{
+    assert(std::size_t(m) % 16 == 0);
+    return { vld1q_f32(m) };
+}
+
+static inline void gmx_simdcall store4(float* m, Simd4Float a)
+{
+    assert(std::size_t(m) % 16 == 0);
+    vst1q_f32(m, a.simdInternal_);
+}
+
+static inline Simd4Float gmx_simdcall load4U(const float* m)
+{
+    return { vld1q_f32(m) };
+}
+
+static inline void gmx_simdcall store4U(float* m, Simd4Float a)
+{
+    vst1q_f32(m, a.simdInternal_);
+}
+
+static inline Simd4Float gmx_simdcall simd4SetZeroF()
+{
+    return { vdupq_n_f32(0.0f) };
+}
+
+static inline Simd4Float gmx_simdcall operator&(Simd4Float a, Simd4Float b)
+{
+    return { vreinterpretq_f32_s32(vandq_s32(vreinterpretq_s32_f32(a.simdInternal_),
+                                             vreinterpretq_s32_f32(b.simdInternal_))) };
+}
+
+static inline Simd4Float gmx_simdcall andNot(Simd4Float a, Simd4Float b)
+{
+    return { vreinterpretq_f32_s32(vbicq_s32(vreinterpretq_s32_f32(b.simdInternal_),
+                                             vreinterpretq_s32_f32(a.simdInternal_))) };
+}
+
+static inline Simd4Float gmx_simdcall operator|(Simd4Float a, Simd4Float b)
+{
+    return { vreinterpretq_f32_s32(vorrq_s32(vreinterpretq_s32_f32(a.simdInternal_),
+                                             vreinterpretq_s32_f32(b.simdInternal_))) };
+}
+
+static inline Simd4Float gmx_simdcall operator^(Simd4Float a, Simd4Float b)
+{
+    return { vreinterpretq_f32_s32(veorq_s32(vreinterpretq_s32_f32(a.simdInternal_),
+                                             vreinterpretq_s32_f32(b.simdInternal_))) };
+}
+
+static inline Simd4Float gmx_simdcall operator+(Simd4Float a, Simd4Float b)
+{
+    return { vaddq_f32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall operator-(Simd4Float a, Simd4Float b)
+{
+    return { vsubq_f32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall operator-(Simd4Float a)
+{
+    return { vnegq_f32(a.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall operator*(Simd4Float a, Simd4Float b)
+{
+    return { vmulq_f32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall fma(Simd4Float a, Simd4Float b, Simd4Float c)
+{
+    return { vfmaq_f32(c.simdInternal_, b.simdInternal_, a.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall fms(Simd4Float a, Simd4Float b, Simd4Float c)
+{
+    return { vnegq_f32(vfmsq_f32(c.simdInternal_, b.simdInternal_, a.simdInternal_)) };
+}
+
+static inline Simd4Float gmx_simdcall fnma(Simd4Float a, Simd4Float b, Simd4Float c)
+{
+    return { vfmsq_f32(c.simdInternal_, b.simdInternal_, a.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall fnms(Simd4Float a, Simd4Float b, Simd4Float c)
+{
+    return { vnegq_f32(vfmaq_f32(c.simdInternal_, b.simdInternal_, a.simdInternal_)) };
+}
+
+static inline Simd4Float gmx_simdcall rsqrt(Simd4Float x)
+{
+    return { vrsqrteq_f32(x.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall abs(Simd4Float x)
+{
+    return { vabsq_f32(x.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall max(Simd4Float a, Simd4Float b)
+{
+    return { vmaxq_f32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall min(Simd4Float a, Simd4Float b)
+{
+    return { vminq_f32(a.simdInternal_, b.simdInternal_) };
+}
+
+// Round and trunc operations are defined at the end of this file, since they
+// need to use float-to-integer and integer-to-float conversions.
+
+static inline float gmx_simdcall reduce(Simd4Float a)
+{
+    float32x4_t b = a.simdInternal_;
+    b             = vpaddq_f32(b, b);
+    b             = vpaddq_f32(b, b);
+    return vgetq_lane_f32(b, 0);
+}
+
+static inline Simd4FBool gmx_simdcall operator==(Simd4Float a, Simd4Float b)
+{
+    return { vceqq_f32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4FBool gmx_simdcall operator!=(Simd4Float a, Simd4Float b)
+{
+    return { vmvnq_u32(vceqq_f32(a.simdInternal_, b.simdInternal_)) };
+}
+
+static inline Simd4FBool gmx_simdcall operator<(Simd4Float a, Simd4Float b)
+{
+    return { vcltq_f32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4FBool gmx_simdcall operator<=(Simd4Float a, Simd4Float b)
+{
+    return { vcleq_f32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4FBool gmx_simdcall operator&&(Simd4FBool a, Simd4FBool b)
+{
+    return { vandq_u32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline Simd4FBool gmx_simdcall operator||(Simd4FBool a, Simd4FBool b)
+{
+    return { vorrq_u32(a.simdInternal_, b.simdInternal_) };
+}
+
+static inline bool gmx_simdcall anyTrue(Simd4FBool a)
+{
+    return (vmaxvq_u32(a.simdInternal_) != 0);
+}
+
+static inline Simd4Float gmx_simdcall selectByMask(Simd4Float a, Simd4FBool m)
+{
+    return { vreinterpretq_f32_u32(vandq_u32(vreinterpretq_u32_f32(a.simdInternal_), m.simdInternal_)) };
+}
+
+static inline Simd4Float gmx_simdcall selectByNotMask(Simd4Float a, Simd4FBool m)
+{
+    return { vreinterpretq_f32_u32(vbicq_u32(vreinterpretq_u32_f32(a.simdInternal_), m.simdInternal_)) };
+}
+
+static inline Simd4Float gmx_simdcall blend(Simd4Float a, Simd4Float b, Simd4FBool sel)
+{
+    return { vbslq_f32(sel.simdInternal_, b.simdInternal_, a.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall round(Simd4Float x)
+{
+    return { vrndnq_f32(x.simdInternal_) };
+}
+
+static inline Simd4Float gmx_simdcall trunc(Simd4Float x)
+{
+    return { vrndq_f32(x.simdInternal_) };
+}
+
+static inline float gmx_simdcall dotProduct(Simd4Float a, Simd4Float b)
+{
+    Simd4Float c;
+
+    c = a * b;
+    /* set 4th element to 0, then add all of them */
+    c.simdInternal_ = vsetq_lane_f32(0.0f, c.simdInternal_, 3);
+    return reduce(c);
+}
+
+static inline void gmx_simdcall transpose(Simd4Float* v0, Simd4Float* v1, Simd4Float* v2, Simd4Float* v3)
+{
+    float32x4x2_t t0  = vuzpq_f32(v0->simdInternal_, v2->simdInternal_);
+    float32x4x2_t t1  = vuzpq_f32(v1->simdInternal_, v3->simdInternal_);
+    float32x4x2_t t2  = vtrnq_f32(t0.val[0], t1.val[0]);
+    float32x4x2_t t3  = vtrnq_f32(t0.val[1], t1.val[1]);
+    v0->simdInternal_ = t2.val[0];
+    v1->simdInternal_ = t3.val[0];
+    v2->simdInternal_ = t2.val[1];
+    v3->simdInternal_ = t3.val[1];
+}
+#endif
+
+} // namespace gmx
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_SIMD4_FLOAT_H
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd_double.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd_double.h
new file mode 100644
index 0000000..dcf502a
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd_double.h
@@ -0,0 +1,746 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_SIMD_DOUBLE_H
+#define GMX_SIMD_IMPL_ARM_SVE_SIMD_DOUBLE_H
+
+#include "config.h"
+
+#include <cassert>
+#include <cstddef>
+#include <cstdint>
+
+#include <arm_sve.h>
+
+#include "gromacs/math/utilities.h"
+
+#if GMX_SIMD_ARM_SVE_FULL_LENGTH
+#    define SVE_DOUBLE_MASK svptrue_b64()
+#    define SVE_DINT32_MASK svptrue_b64()
+#else
+#    define SVE_DOUBLE_MASK svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH)
+#    define SVE_DINT32_MASK svwhilelt_b64(0, (int32_t)GMX_SIMD_DINT32_WIDTH)
+#endif
+
+namespace gmx
+{
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct SimdDouble
+#else
+typedef __sizeless_struct SimdDouble
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    float64_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+#else
+    svfloat64_t simdInternal_;
+#endif
+
+    SimdDouble(const double d) { this->simdInternal_ = svdup_f64(d); }
+
+    SimdDouble(svfloat64_t simd) : simdInternal_(simd) {}
+
+    SimdDouble() {}
+} SimdDouble;
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct SimdDInt32
+#else
+typedef __sizeless_struct SimdDInt32
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    int64_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+#else
+    svint64_t simdInternal_;
+#endif
+
+    SimdDInt32(const int32_t i) { this->simdInternal_ = svdup_s64(i); }
+
+    SimdDInt32(svint64_t simd) : simdInternal_(simd) {}
+
+    SimdDInt32() {}
+} SimdDInt32;
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct SimdDBool
+#else
+typedef __sizeless_struct SimdDBool
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    uint64_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+
+    SimdDBool(const bool b) { this->simdInternal_ = svdup_n_u64_z(svptrue_b64(), b ? 1 : 0); }
+
+    SimdDBool(svbool_t simd) { this->simdInternal_ = svdup_n_u64_z(simd, 1); }
+#else
+    svbool_t simdInternal_;
+
+    SimdDBool(const bool b)
+    {
+        if (b)
+        {
+            this->simdInternal_ = svptrue_b64();
+        }
+        else
+        {
+            this->simdInternal_ = svpfalse_b();
+        }
+    }
+
+    SimdDBool(svbool_t simd) : simdInternal_(simd) {}
+#endif
+
+    SimdDBool() {}
+} SimdDBool;
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct SimdDIBool
+#else
+typedef __sizeless_struct SimdDIBool
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    uint64_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+
+    SimdDIBool(const bool b) { this->simdInternal_ = svdup_n_u64_z(svptrue_b64(), b ? 1 : 0); }
+
+    SimdDIBool(svbool_t simd) { this->simdInternal_ = svdup_n_u64_z(simd, 1); }
+#else
+    svbool_t simdInternal_;
+
+    SimdDIBool(svbool_t simd) : simdInternal_(simd) {}
+#endif
+} SimdDIBool;
+
+#if GMX_SIMD_ARM_SVE_GNU
+static inline svbool_t getMask(SimdDBool m)
+{
+    return svcmpne_n_u64(svptrue_b64(), m.simdInternal_, 0);
+}
+
+static inline svbool_t getMask(SimdDIBool m)
+{
+    return svcmpne_n_u64(svptrue_b64(), m.simdInternal_, 0);
+}
+#endif
+
+static inline SimdDouble gmx_simdcall simdLoad(const double* m, SimdDoubleTag = {})
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_DOUBLE_MASK;
+    return { svld1_f64(pg, m) };
+}
+
+static inline SimdDouble gmx_simdcall simdLoad(SimdDouble* m, int offset, SimdDoubleTag = {})
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_DOUBLE_MASK;
+    return { svld1_f64(pg, reinterpret_cast<double*>(m) + offset * svcntd()) };
+}
+
+static inline SimdDouble gmx_simdcall simdLoadDouble(const double* m)
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_DOUBLE_MASK;
+    return { svld1_f64(pg, m) };
+}
+
+static inline void gmx_simdcall store(double* m, SimdDouble a)
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_DOUBLE_MASK;
+    svst1_f64(pg, m, a.simdInternal_);
+}
+
+static inline SimdDouble gmx_simdcall simdLoadU(const double* m, SimdDoubleTag = {})
+{
+    svbool_t pg = SVE_DOUBLE_MASK;
+    return { svld1_f64(pg, m) };
+}
+
+static inline void gmx_simdcall storeU(double* m, SimdDouble a)
+{
+    svbool_t pg = SVE_DOUBLE_MASK;
+    svst1_f64(pg, m, a.simdInternal_);
+}
+
+static inline SimdDouble gmx_simdcall setZeroD()
+{
+    return { svdup_f64(0.0) };
+}
+
+static inline void gmx_simdcall simdIncr(SimdDouble*& p, SimdDoubleTag)
+{
+    p = reinterpret_cast<SimdDouble*>(reinterpret_cast<uint64_t>(p) + svcntw());
+}
+
+static inline SimdDInt32 gmx_simdcall simdLoad(const std::int32_t* m, SimdDInt32Tag)
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH);
+    return { svunpklo_s64(svld1_s32(pg, m)) };
+}
+
+static inline void gmx_simdcall store(std::int32_t* m, SimdDInt32 a)
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH);
+    svst1_s32(pg, m,
+              svuzp1(svreinterpret_s32_s64(a.simdInternal_), svreinterpret_s32_s64(a.simdInternal_)));
+}
+
+static inline SimdDInt32 gmx_simdcall simdLoadU(const std::int32_t* m, SimdDInt32Tag)
+{
+    svbool_t pg = svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH);
+    return { svunpklo_s64(svld1_s32(pg, m)) };
+}
+
+static inline void gmx_simdcall storeU(std::int32_t* m, SimdDInt32 a)
+{
+    svbool_t pg = svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH);
+    svst1_s32(pg, m,
+              svuzp1(svreinterpret_s32_s64(a.simdInternal_), svreinterpret_s32_s64(a.simdInternal_)));
+}
+
+static inline SimdDInt32 gmx_simdcall setZeroDI()
+{
+    return { svdup_s64(0) };
+}
+
+template<int index>
+gmx_simdcall static inline std::int32_t extract(SimdDInt32 a)
+{
+    svbool_t pg = svwhilelt_b64(0, index);
+    return svlasta_s64(pg, a.simdInternal_);
+}
+
+template<int index>
+gmx_simdcall static inline double extract(SimdDouble a)
+{
+    svbool_t pg = svwhilelt_b64(0, index);
+    return svlasta_f64(pg, a.simdInternal_);
+}
+
+static inline SimdDouble gmx_simdcall operator&(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svreinterpret_f64_s64(svand_s64_z(pg, svreinterpret_s64_f64(a.simdInternal_),
+                                               svreinterpret_s64_f64(b.simdInternal_))) };
+}
+
+static inline SimdDouble gmx_simdcall andNot(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svreinterpret_f64_s64(svbic_s64_z(pg, svreinterpret_s64_f64(b.simdInternal_),
+                                               svreinterpret_s64_f64(a.simdInternal_))) };
+}
+
+static inline SimdDouble gmx_simdcall operator|(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svreinterpret_f64_s64(svorr_s64_z(pg, svreinterpret_s64_f64(a.simdInternal_),
+                                               svreinterpret_s64_f64(b.simdInternal_))) };
+}
+
+static inline SimdDouble gmx_simdcall operator^(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svreinterpret_f64_s64(sveor_s64_z(pg, svreinterpret_s64_f64(a.simdInternal_),
+                                               svreinterpret_s64_f64(b.simdInternal_))) };
+}
+
+static inline SimdDouble gmx_simdcall operator+(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svadd_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall operator-(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svsub_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall operator-(SimdDouble a)
+{
+    svbool_t pg = svptrue_b64();
+    return { svneg_f64_z(pg, a.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall operator*(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmul_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+#define simdIncDouble(p) p = reinterpret_cast<SimdDouble*>(reinterpret_cast<uint64_t>(p) + svcntd())
+
+#define simdOffsetDouble(p, o) \
+    reinterpret_cast<SimdDouble*>(reinterpret_cast<uint64_t>(p) + o * svcntd())
+
+static inline SimdDouble gmx_simdcall fma(SimdDouble a, SimdDouble b, SimdDouble c)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmad_f64_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall fms(SimdDouble a, SimdDouble b, SimdDouble c)
+{
+    svbool_t pg = svptrue_b64();
+    return { svnmsb_f64_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall fnma(SimdDouble a, SimdDouble b, SimdDouble c)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmsb_f64_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall fnms(SimdDouble a, SimdDouble b, SimdDouble c)
+{
+    svbool_t pg = svptrue_b64();
+    return { svnmad_f64_z(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall rsqrt(SimdDouble x)
+{
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    x.simdInternal_ = svsplice_f64(SVE_DOUBLE_MASK, x.simdInternal_, svdup_n_f64(1.0));
+#endif
+    return { svrsqrte_f64(x.simdInternal_) };
+}
+
+// The SIMD implementation seems to overflow when we square lu for
+// values close to FLOAT_MAX, so we fall back on the version in
+// simd_math.h, which is probably slightly slower.
+#if GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_DOUBLE
+static inline SimdDouble gmx_simdcall rsqrtIter(SimdDouble lu, SimdDouble x)
+{
+    return { vmulq_f64(lu.simdInternal_,
+                       vrsqrtsq_f32(vmulq_f32(lu.simdInternal_, lu.simdInternal_), x.simdInternal_)) };
+}
+#endif
+
+static inline SimdDouble gmx_simdcall rcp(SimdDouble x)
+{
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    x.simdInternal_ = svsplice_f64(SVE_DOUBLE_MASK, x.simdInternal_, svdup_n_f64(1.0));
+#endif
+    return { svrecpe_f64(x.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall rcpIter(SimdDouble lu, SimdDouble x)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmul_f64_z(pg, lu.simdInternal_, svrecps_f64(lu.simdInternal_, x.simdInternal_)) };
+}
+
+static inline SimdDouble gmx_simdcall maskAdd(SimdDouble a, SimdDouble b, SimdDBool m)
+{
+    return { svadd_f64_m(getMask(m), a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall maskzMul(SimdDouble a, SimdDouble b, SimdDBool m)
+{
+    return { svmul_f64_z(getMask(m), a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall maskzFma(SimdDouble a, SimdDouble b, SimdDouble c, SimdDBool m)
+{
+    return { svmad_f64_z(getMask(m), a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall maskzRsqrt(SimdDouble x, SimdDBool m)
+{
+    // The result will always be correct since we mask the result with m, but
+    // for debug builds we also want to make sure not to generate FP exceptions
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    m = svand_b_z(svptrue_b64(), getMask(m), SVE_DOUBLE_MASK);
+#endif
+#ifndef NDEBUG
+    x.simdInternal_ = svsel_f64(getMask(m), x.simdInternal_, svdup_n_f64(1.0));
+#endif
+    return { svreinterpret_f64_u64(svand_n_u64_z(
+            getMask(m), svreinterpret_u64_f64(svrsqrte_f64(x.simdInternal_)), 0xFFFFFFFFFFFFFFFF)) };
+}
+
+static inline SimdDouble gmx_simdcall maskzRcp(SimdDouble x, SimdDBool m)
+{
+    // The result will always be correct since we mask the result with m, but
+    // for debug builds we also want to make sure not to generate FP exceptions
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    m = svand_b_z(svptrue_b64(), getMask(m), SVE_DOUBLE_MASK);
+#endif
+#ifndef NDEBUG
+    x.simdInternal_ = svsel_f64(getMask(m), x.simdInternal_, svdup_n_f64(1.0));
+#endif
+    return { svreinterpret_f64_u64(svand_n_u64_z(
+            getMask(m), svreinterpret_u64_f64(svrecpe_f64(x.simdInternal_)), 0xFFFFFFFFFFFFFFFF)) };
+}
+
+static inline SimdDouble gmx_simdcall abs(SimdDouble x)
+{
+    svbool_t pg = svptrue_b64();
+    return { svabs_f64_z(pg, x.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall max(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmax_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall min(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmin_f64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+// Round and trunc operations are defined at the end of this file, since they
+// need to use double-to-integer and integer-to-double conversions.
+
+static inline SimdDouble gmx_simdcall frexp(SimdDouble value, SimdDInt32* exponent)
+{
+    svbool_t        pg           = svptrue_b64();
+    const svint64_t exponentMask = svdup_n_s64(0x7FF0000000000000LL);
+    const svint64_t mantissaMask = svdup_n_s64(0x800FFFFFFFFFFFFFLL);
+    const svint64_t exponentBias = svdup_n_s64(1022LL); // add 1 to make our definition identical to frexp()
+    const svfloat64_t half = svdup_n_f64(0.5);
+    svint64_t         iExponent;
+
+    iExponent = svand_s64_z(pg, svreinterpret_s64_f64(value.simdInternal_), exponentMask);
+    // iExponent               = svsub_s64_z(pg, svlsr_n_s64_z(pg, iExponent, 52), exponentBias);
+    iExponent = svsub_s64_z(
+            pg, svreinterpret_s64_u64(svlsr_n_u64_z(pg, svreinterpret_u64_s64(iExponent), 52)), exponentBias);
+
+    exponent->simdInternal_ = iExponent;
+
+    return { svreinterpret_f64_s64(svorr_s64_z(
+            pg, svand_s64_z(pg, svreinterpret_s64_f64(value.simdInternal_), mantissaMask),
+            svreinterpret_s64_f64(half))) };
+}
+
+template<MathOptimization opt = MathOptimization::Safe>
+static inline SimdDouble gmx_simdcall ldexp(SimdDouble value, SimdDInt32 exponent)
+{
+    svbool_t        pg           = svptrue_b64();
+    const svint64_t exponentBias = svdup_n_s64(1023);
+    svint64_t       iExponent    = svadd_s64_z(pg, exponent.simdInternal_, exponentBias);
+
+    if (opt == MathOptimization::Safe)
+    {
+        // Make sure biased argument is not negative
+        iExponent = svmax_n_s64_z(pg, iExponent, 0);
+    }
+
+    iExponent = svlsl_n_s64_z(pg, iExponent, 52);
+
+    return { svmul_f64_z(pg, value.simdInternal_, svreinterpret_f64_s64(iExponent)) };
+}
+
+static inline double gmx_simdcall reduce(SimdDouble a)
+{
+    svbool_t pg = svptrue_b64();
+    return svadda_f64(pg, 0.0f, a.simdInternal_);
+}
+
+static inline SimdDBool gmx_simdcall operator==(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmpeq_f64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDBool gmx_simdcall operator!=(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmpne_f64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDBool gmx_simdcall operator<(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmplt_f64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDBool gmx_simdcall operator<=(SimdDouble a, SimdDouble b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmple_f64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDBool gmx_simdcall testBits(SimdDouble a)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmpne_n_s64(pg, svreinterpret_s64_f64(a.simdInternal_), 0) };
+}
+
+static inline SimdDBool gmx_simdcall operator&&(SimdDBool a, SimdDBool b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svand_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline SimdDBool gmx_simdcall operator||(SimdDBool a, SimdDBool b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svorr_b_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline bool gmx_simdcall anyTrue(SimdDBool a)
+{
+    svbool_t pg = svptrue_b64();
+    return svptest_any(pg, getMask(a));
+}
+
+static inline bool gmx_simdcall extractFirst(SimdDBool a)
+{
+    svbool_t pg = svptrue_b64();
+    return svptest_first(pg, getMask(a));
+}
+
+static inline SimdDouble gmx_simdcall selectByMask(SimdDouble a, SimdDBool m)
+{
+    return { svsel_f64(getMask(m), a.simdInternal_, svdup_f64(0.0)) };
+}
+
+static inline SimdDouble gmx_simdcall selectByNotMask(SimdDouble a, SimdDBool m)
+{
+    svbool_t pg = svptrue_b64();
+    return { svsel_f64(sveor_b_z(pg, getMask(m), pg), a.simdInternal_, svdup_f64(0.0)) };
+}
+
+static inline SimdDouble gmx_simdcall blend(SimdDouble a, SimdDouble b, SimdDBool sel)
+{
+    return { svsel_f64(getMask(sel), b.simdInternal_, a.simdInternal_) };
+}
+
+static inline SimdDInt32 gmx_simdcall operator&(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svand_s64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDInt32 gmx_simdcall andNot(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svbic_s64_z(pg, b.simdInternal_, a.simdInternal_) };
+}
+
+static inline SimdDInt32 gmx_simdcall operator|(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svorr_s64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDInt32 gmx_simdcall operator^(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { sveor_s64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDInt32 gmx_simdcall operator+(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svadd_s64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDInt32 gmx_simdcall operator-(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svsub_s64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDInt32 gmx_simdcall operator*(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svmul_s64_z(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDIBool gmx_simdcall operator==(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmpeq_s64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDIBool gmx_simdcall testBits(SimdDInt32 a)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmpne_n_s64(pg, a.simdInternal_, (int64_t)0) };
+}
+
+static inline SimdDIBool gmx_simdcall operator<(SimdDInt32 a, SimdDInt32 b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcmplt_s64(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdDIBool gmx_simdcall operator&&(SimdDIBool a, SimdDIBool b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svand_b_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline SimdDIBool gmx_simdcall operator||(SimdDIBool a, SimdDIBool b)
+{
+    svbool_t pg = svptrue_b64();
+    return { svorr_b_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline bool gmx_simdcall anyTrue(SimdDIBool a)
+{
+    svbool_t pg = svptrue_b64();
+    return svptest_any(pg, getMask(a));
+}
+
+static inline SimdDInt32 gmx_simdcall selectByMask(SimdDInt32 a, SimdDIBool m)
+{
+    return { svadd_n_s64_z(getMask(m), a.simdInternal_, 0) };
+}
+
+static inline SimdDInt32 gmx_simdcall selectByNotMask(SimdDInt32 a, SimdDIBool m)
+{
+    svbool_t pg = svptrue_b64();
+    return { svadd_n_s64_z(sveor_b_z(pg, getMask(m), pg), a.simdInternal_, 0) };
+}
+
+static inline SimdDInt32 gmx_simdcall blend(SimdDInt32 a, SimdDInt32 b, SimdDIBool sel)
+{
+    return { svsel_s64(getMask(sel), b.simdInternal_, a.simdInternal_) };
+}
+
+static inline SimdDInt32 gmx_simdcall cvtR2I(SimdDouble a)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcvt_s64_z(pg, svrinta_f64_z(pg, a.simdInternal_)) };
+}
+
+static inline SimdDInt32 gmx_simdcall cvttR2I(SimdDouble a)
+{
+    // FIXME ???
+    svbool_t pg = svptrue_b64();
+    return { svcvt_s64_z(pg, a.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall cvtI2R(SimdDInt32 a)
+{
+    svbool_t pg = svptrue_b64();
+    return { svcvt_f64_z(pg, a.simdInternal_) };
+}
+
+static inline SimdDIBool gmx_simdcall cvtB2IB(SimdDBool a)
+{
+    return { getMask(a) };
+}
+
+static inline SimdDBool gmx_simdcall cvtIB2B(SimdDIBool a)
+{
+    return { getMask(a) };
+}
+
+static inline SimdDouble gmx_simdcall round(SimdDouble x)
+{
+    svbool_t pg = svptrue_b64();
+    return { svrinta_f64_z(pg, x.simdInternal_) };
+}
+
+static inline SimdDouble gmx_simdcall trunc(SimdDouble x)
+{
+    return cvtI2R(cvttR2I(x));
+}
+
+static inline void gmx_simdcall cvtF2DD(SimdFloat gmx_unused f,
+                                        SimdDouble gmx_unused* d0,
+                                        SimdDouble gmx_unused* d1)
+{
+    assert(GMX_SIMD_FLOAT_WIDTH == 2 * GMX_SIMD_DOUBLE_WIDTH);
+    svbool_t pg = SVE_FLOAT_MASK;
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    f.simdInternal_ =
+            svsplice_f32(svwhilelt_b32(0, (int32_t)svcntw() / 2), f.simdInternal_,
+                         svext_f32(f.simdInternal_, f.simdInternal_, GMX_SIMD_FLOAT_WIDTH / 2));
+#endif
+    d0->simdInternal_ = svcvt_f64_f32_z(pg, svzip1(f.simdInternal_, f.simdInternal_));
+    d1->simdInternal_ = svcvt_f64_f32_z(pg, svzip2(f.simdInternal_, f.simdInternal_));
+}
+
+static inline SimdFloat gmx_simdcall cvtDD2F(SimdDouble gmx_unused d0, SimdDouble gmx_unused d1)
+{
+    SimdFloat res;
+    svbool_t  pg = svptrue_b64();
+    assert(GMX_SIMD_FLOAT_WIDTH == 2 * GMX_SIMD_DOUBLE_WIDTH);
+    res.simdInternal_ =
+            svuzp1_f32(svcvt_f32_f64_z(pg, d0.simdInternal_), svcvt_f32_f64_z(pg, d1.simdInternal_));
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    switch (svcntw())
+    {
+        case 8:
+            res.simdInternal_ = svsplice_f32(svwhilelt_b32(0, (int32_t)GMX_SIMD_FLOAT_WIDTH / 2),
+                                             res.simdInternal_,
+                                             svext_f32(res.simdInternal_, res.simdInternal_, 4));
+            break;
+        case 16:
+            res.simdInternal_ = svsplice_f32(svwhilelt_b32(0, (int32_t)GMX_SIMD_FLOAT_WIDTH / 2),
+                                             res.simdInternal_,
+                                             svext_f32(res.simdInternal_, res.simdInternal_, 8));
+            break;
+        case 32:
+            res.simdInternal_ = svsplice_f32(svwhilelt_b32(0, (int32_t)GMX_SIMD_FLOAT_WIDTH / 2),
+                                             res.simdInternal_,
+                                             svext_f32(res.simdInternal_, res.simdInternal_, 16));
+            break;
+        case 64:
+            res.simdInternal_ = svsplice_f32(svwhilelt_b32(0, (int32_t)GMX_SIMD_FLOAT_WIDTH / 2),
+                                             res.simdInternal_,
+                                             svext_f32(res.simdInternal_, res.simdInternal_, 32));
+            break;
+        default: assert(0);
+    }
+
+#endif
+    return res;
+}
+
+} // namespace gmx
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_SIMD_DOUBLE_H
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd_float.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd_float.h
new file mode 100644
index 0000000..f6e7e8b
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_simd_float.h
@@ -0,0 +1,752 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_SIMD_FLOAT_H
+#define GMX_SIMD_IMPL_ARM_SVE_SIMD_FLOAT_H
+
+#include "config.h"
+
+#include <cassert>
+#include <cstddef>
+#include <cstdint>
+
+#include <arm_sve.h>
+
+#include "gromacs/math/utilities.h"
+
+#if GMX_SIMD_ARM_SVE_FULL_LENGTH
+#    define SVE_FLOAT_MASK svptrue_b32()
+#    define SVE_FINT32_MASK svptrue_b32()
+#else
+#    define SVE_FLOAT_MASK svwhilelt_b32(0, (int32_t)GMX_SIMD_FLOAT_WIDTH)
+#    define SVE_FINT32_MASK svwhilelt_b32(0, (int32_t)GMX_SIMD_FINT32_WIDTH)
+#endif
+
+namespace gmx
+{
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct SimdFloat
+#else
+typedef __sizeless_struct SimdFloat
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    float32_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+#else
+    svfloat32_t simdInternal_;
+#endif
+
+    SimdFloat(const float f) { this->simdInternal_ = svdup_f32(f); }
+
+    SimdFloat(svfloat32_t simd) : simdInternal_(simd) {}
+
+    SimdFloat() {}
+} SimdFloat;
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct SimdFInt32
+#else
+typedef __sizeless_struct SimdFInt32
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    int32_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+#else
+    svint32_t simdInternal_;
+#endif
+
+    SimdFInt32(const int32_t i) { this->simdInternal_ = svdup_s32(i); }
+
+    SimdFInt32(svint32_t simd) : simdInternal_(simd) {}
+
+    SimdFInt32() {}
+} SimdFInt32;
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct SimdFBool
+#else
+typedef __sizeless_struct SimdFBool
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    uint32_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+
+    SimdFBool(const bool b) { this->simdInternal_ = svdup_n_u32_z(svptrue_b32(), b ? 1 : 0); }
+
+    SimdFBool(svbool_t simd) { this->simdInternal_ = svdup_n_u32_z(simd, 1); }
+#else
+    svbool_t simdInternal_;
+
+    SimdFBool(const bool b)
+    {
+        if (b)
+        {
+            this->simdInternal_ = svptrue_b32();
+        }
+        else
+        {
+            this->simdInternal_ = svpfalse_b();
+        }
+    }
+
+    SimdFBool(svbool_t simd) : simdInternal_(simd) {}
+#endif
+
+    SimdFBool() {}
+} SimdFBool;
+
+#if GMX_SIMD_ARM_SVE_GNU
+typedef struct SimdFIBool
+#else
+typedef __sizeless_struct SimdFIBool
+#endif
+{
+#if GMX_SIMD_ARM_SVE_GNU
+    uint32_t simdInternal_ __attribute__((vector_size(GMX_SIMD_ARM_SVE_LENGTH / 8)));
+
+    SimdFIBool(const bool b) { this->simdInternal_ = svdup_n_u32_z(svptrue_b32(), b ? 1 : 0); }
+
+    SimdFIBool(svbool_t simd) { this->simdInternal_ = svdup_n_u32_z(simd, 1); }
+#else
+    svbool_t simdInternal_;
+
+    SimdFIBool(svbool_t simd) : simdInternal_(simd) {}
+#endif
+} SimdFIBool;
+
+#if GMX_SIMD_ARM_SVE_GNU
+static inline svbool_t getMask(SimdFBool m)
+{
+    return svcmpne_n_u32(svptrue_b32(), m.simdInternal_, 0);
+}
+
+static inline svbool_t getMask(SimdFIBool m)
+{
+    return svcmpne_n_u32(svptrue_b32(), m.simdInternal_, 0);
+}
+#else
+#    define getMask(m) (m).simdInternal_
+#endif
+
+static inline SimdFloat gmx_simdcall simdLoad(const float* m, SimdFloatTag = {})
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_FLOAT_MASK;
+    return { svld1_f32(pg, m) };
+}
+
+static inline SimdFloat gmx_simdcall simdLoad(SimdFloat* m, int offset, SimdFloatTag = {})
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_FLOAT_MASK;
+    return { svld1_f32(pg, reinterpret_cast<float*>(m) + offset * svcntw()) };
+}
+
+static inline SimdFloat gmx_simdcall simdLoadFloat(const float* m)
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_FLOAT_MASK;
+    return { svld1_f32(pg, m) };
+}
+
+static inline void gmx_simdcall store(float* m, SimdFloat a)
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_FLOAT_MASK;
+    svst1_f32(pg, m, a.simdInternal_);
+}
+
+static inline SimdFloat gmx_simdcall simdLoadU(const float* m, SimdFloatTag = {})
+{
+    svbool_t pg = SVE_FLOAT_MASK;
+    return { svld1_f32(pg, m) };
+}
+
+static inline void gmx_simdcall storeU(float* m, SimdFloat a)
+{
+    svbool_t pg = SVE_FLOAT_MASK;
+    svst1_f32(pg, m, a.simdInternal_);
+}
+
+static inline SimdFloat gmx_simdcall setZeroF()
+{
+    return { svdup_f32(0.0f) };
+}
+
+static inline void gmx_simdcall simdIncr(SimdFloat*& p, SimdFloatTag)
+{
+    p = reinterpret_cast<SimdFloat*>(reinterpret_cast<uint64_t>(p) + svcntw());
+}
+
+static inline SimdFInt32 gmx_simdcall simdLoad(const std::int32_t* m, SimdFInt32Tag)
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_FINT32_MASK;
+    return { svld1_s32(pg, m) };
+}
+
+static inline void gmx_simdcall store(std::int32_t* m, SimdFInt32 a)
+{
+    assert(0 == (std::size_t(m) % GMX_SIMD_ALIGNMENT));
+    svbool_t pg = SVE_FINT32_MASK;
+    svst1_s32(pg, m, a.simdInternal_);
+}
+
+static inline SimdFInt32 gmx_simdcall simdLoadU(const std::int32_t* m, SimdFInt32Tag)
+{
+    svbool_t pg = SVE_FINT32_MASK;
+    return { svld1_s32(pg, m) };
+}
+
+static inline void gmx_simdcall storeU(std::int32_t* m, SimdFInt32 a)
+{
+    svbool_t pg = SVE_FINT32_MASK;
+    svst1_s32(pg, m, a.simdInternal_);
+}
+
+static inline SimdFInt32 gmx_simdcall setZeroFI()
+{
+    return { svdup_s32(0) };
+}
+
+template<int index>
+gmx_simdcall static inline std::int32_t extract(SimdFInt32 a)
+{
+    svbool_t pg = svwhilelt_b32(0, index);
+    return svlasta_s32(pg, a.simdInternal_);
+}
+
+template<int index>
+gmx_simdcall static inline float extract(SimdFloat a)
+{
+    svbool_t pg = svwhilelt_b32(0, index);
+    return svlasta_f32(pg, a.simdInternal_);
+}
+
+static inline SimdFloat gmx_simdcall operator&(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svreinterpret_f32_s32(svand_s32_x(pg, svreinterpret_s32_f32(a.simdInternal_),
+                                               svreinterpret_s32_f32(b.simdInternal_))) };
+}
+
+static inline SimdFloat gmx_simdcall andNot(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svreinterpret_f32_s32(svbic_s32_x(pg, svreinterpret_s32_f32(b.simdInternal_),
+                                               svreinterpret_s32_f32(a.simdInternal_))) };
+}
+
+static inline SimdFloat gmx_simdcall operator|(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svreinterpret_f32_s32(svorr_s32_x(pg, svreinterpret_s32_f32(a.simdInternal_),
+                                               svreinterpret_s32_f32(b.simdInternal_))) };
+}
+
+static inline SimdFloat gmx_simdcall operator^(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svreinterpret_f32_s32(sveor_s32_x(pg, svreinterpret_s32_f32(a.simdInternal_),
+                                               svreinterpret_s32_f32(b.simdInternal_))) };
+}
+
+static inline SimdFloat gmx_simdcall operator+(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svadd_f32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall operator-(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svsub_f32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall operator-(SimdFloat a)
+{
+    svbool_t pg = svptrue_b32();
+    return { svneg_f32_x(pg, a.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall operator*(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = SVE_FLOAT_MASK;
+    return { svmul_f32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+#define simdIncFloat(p) p = reinterpret_cast<SimdFloat*>(reinterpret_cast<uint64_t>(p) + svcntw())
+
+#define simdOffsetFloat(p, o) \
+    reinterpret_cast<SimdFloat*>(reinterpret_cast<uint64_t>(p) + o * svcntw())
+
+static inline SimdFloat gmx_simdcall fma(SimdFloat a, SimdFloat b, SimdFloat c)
+{
+    svbool_t pg = svptrue_b32();
+    return { svmad_f32_x(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall fms(SimdFloat a, SimdFloat b, SimdFloat c)
+{
+    svbool_t pg = svptrue_b32();
+    return { svnmsb_f32_x(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall fnma(SimdFloat a, SimdFloat b, SimdFloat c)
+{
+    svbool_t pg = svptrue_b32();
+    return { svmsb_f32_x(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall fnms(SimdFloat a, SimdFloat b, SimdFloat c)
+{
+    svbool_t pg = svptrue_b32();
+    return { svnmad_f32_x(pg, a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall rsqrt(SimdFloat x)
+{
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    x.simdInternal_ = svsplice_f32(SVE_FLOAT_MASK, x.simdInternal_, svdup_n_f32(1.0f));
+#endif
+    return { svrsqrte_f32(x.simdInternal_) };
+}
+
+// The SIMD implementation seems to overflow when we square lu for
+// values close to FLOAT_MAX, so we fall back on the version in
+// simd_math.h, which is probably slightly slower.
+#if GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT
+static inline SimdFloat gmx_simdcall rsqrtIter(SimdFloat lu, SimdFloat x)
+{
+    svbool_t pg = SVE_FLOAT_MASK;
+#    if 0
+#        if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    x.simdInternal_ = svsplice_f32(pg, x.simdInternal_, svdup_n_f32(1.0f));
+#        endif
+    return {
+        svmul_f32_x(pg, lu.simdInternal_, svrsqrts_f32(svmul_f32_x(pg, lu.simdInternal_, lu.simdInternal_), x.simdInternal_))
+    };
+#    elif 0
+    svfloat32_t tmp;
+    svfloat32_t onehalf = svdup_f32(1.5f);
+    tmp                 = svmul_f32_x(pg, x.simdInternal_, lu.simdInternal_);
+    tmp                 = svmul_f32_x(pg, tmp, lu.simdInternal_);
+    tmp                 = svmla_n_f32_x(pg, onehalf, tmp, -0.5f);
+    return { svmul_f32_x(pg, tmp, lu.simdInternal_) };
+#    elif 0
+    svfloat32_t tmp1;
+    svfloat32_t mhalf   = svdup_f32(-0.5f);
+    svfloat32_t onehalf = svdup_f32(1.5f);
+    tmp1                = svmul_f32_x(pg, x.simdInternal_, lu.simdInternal_);
+    tmp1                = svmul_f32_x(pg, tmp1, lu.simdInternal_);
+    tmp1                = svmla_f32_x(pg, onehalf, tmp1, mhalf);
+    return { svmul_f32_x(pg, tmp1, lu.simdInternal_) };
+#    elif 0
+    svfloat32_t tmp1, tmp2;
+    tmp1 = svmul_f32_x(pg, x.simdInternal_, lu.simdInternal_);
+    tmp2 = svmul_n_f32_x(pg, lu.simdInternal_, -0.5f);
+    tmp1 = svmla_f32_x(pg, svdup_f32(-3.0f), tmp1, lu.simdInternal_);
+    return { svmul_f32_x(pg, tmp1, tmp2) };
+#    elif 0
+    svfloat32_t tmp1, tmp2;
+    tmp1 = svmul_f32_x(pg, x.simdInternal_, lu.simdInternal_);
+    tmp2 = svmul_f32_x(pg, svdup_f32(-0.5f), lu.simdInternal_);
+    tmp1 = svmla_f32_x(pg, svdup_f32(-3.0f), tmp1, lu.simdInternal_);
+    return { svmul_f32_x(pg, tmp1, tmp2) };
+#    else
+    svfloat32_t tmp1, tmp2;
+    tmp1 = svmul_f32_x(pg, x.simdInternal_, lu.simdInternal_);
+    tmp2 = svmul_n_f32_x(pg, lu.simdInternal_, -0.5f);
+    tmp1 = svmad_n_f32_x(pg, tmp1, lu.simdInternal_, -3.0f);
+    return { svmul_f32_x(pg, tmp1, tmp2) };
+#    endif
+}
+
+#endif
+
+#if 0
+static inline SimdFloat gmx_simdcall
+norm2(SimdFloat ax, SimdFloat ay, SimdFloat az)
+{
+    SimdFloat ret;
+
+    svbool_t pg = SVE_FLOAT_MASK;
+    ret.simdInternal_ = svmul_f32_x(pg, ax.simdInternal_, ax.simdInternal_);
+    ret.simdInternal_ = svmla_f32_x(pg, ret.simdInternal_, ay.simdInternal_, ay.simdInternal_);
+    ret.simdInternal_ = svmla_f32_x(pg, ret.simdInternal_, az.simdInternal_, az.simdInternal_);
+
+    return ret;
+}
+#endif
+
+static inline SimdFloat gmx_simdcall rcp(SimdFloat x)
+{
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    x.simdInternal_ = svsplice_f32(SVE_FLOAT_MASK, x.simdInternal_, svdup_n_f32(1.0f));
+#endif
+    return { svrecpe_f32(x.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall rcpIter(SimdFloat lu, SimdFloat x)
+{
+    svbool_t pg = svptrue_b32();
+    return { svmul_f32_x(pg, lu.simdInternal_, svrecps_f32(lu.simdInternal_, x.simdInternal_)) };
+}
+
+static inline SimdFloat gmx_simdcall maskAdd(SimdFloat a, SimdFloat b, SimdFBool m)
+{
+    return { svadd_f32_m(getMask(m), a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall maskzMul(SimdFloat a, SimdFloat b, SimdFBool m)
+{
+    return { svmul_f32_z(getMask(m), a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall maskzMul(float a, SimdFloat b, SimdFBool m)
+{
+    return { svmul_n_f32_z(getMask(m), b.simdInternal_, a) };
+}
+
+static inline SimdFloat gmx_simdcall maskzFma(SimdFloat a, SimdFloat b, SimdFloat c, SimdFBool m)
+{
+    return { svmad_f32_z(getMask(m), a.simdInternal_, b.simdInternal_, c.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall maskzRsqrt(SimdFloat x, SimdFBool m)
+{
+    // The result will always be correct since we mask the result with m, but
+    // for debug builds we also want to make sure not to generate FP exceptions
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    m = svand_b_z(svptrue_b32(), getMask(m), SVE_FLOAT_MASK);
+#endif
+#ifndef NDEBUG
+    x.simdInternal_ = svsel_f32(getMask(m), x.simdInternal_, svdup_n_f32(1.0f));
+#endif
+    return { svreinterpret_f32_u32(svand_n_u32_z(
+            getMask(m), svreinterpret_u32_f32(svrsqrte_f32(x.simdInternal_)), 0xFFFFFFFF)) };
+}
+
+static inline SimdFloat gmx_simdcall maskzRcp(SimdFloat x, SimdFBool m)
+{
+    // The result will always be correct since we mask the result with m, but
+    // for debug builds we also want to make sure not to generate FP exceptions
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    m = svand_b_z(svptrue_b32(), getMask(m), SVE_FLOAT_MASK);
+#endif
+#ifndef NDEBUG
+    x.simdInternal_ = svsel_f32(getMask(m), x.simdInternal_, svdup_n_f32(1.0f));
+#endif
+    return { svreinterpret_f32_u32(svand_n_u32_z(
+            getMask(m), svreinterpret_u32_f32(svrecpe_f32(x.simdInternal_)), 0xFFFFFFFF)) };
+}
+
+static inline SimdFloat gmx_simdcall abs(SimdFloat x)
+{
+    svbool_t pg = svptrue_b32();
+    return { svabs_f32_x(pg, x.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall max(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svmax_f32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall min(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svmin_f32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+// Round and trunc operations are defined at the end of this file, since they
+// need to use float-to-integer and integer-to-float conversions.
+
+static inline SimdFloat gmx_simdcall frexp(SimdFloat value, SimdFInt32* exponent)
+{
+    svbool_t        pg           = svptrue_b32();
+    const svint32_t exponentMask = svdup_n_s32(0x7F800000);
+    const svint32_t mantissaMask = svdup_n_s32(0x807FFFFF);
+    const svint32_t exponentBias = svdup_n_s32(126); // add 1 to make our definition identical to frexp()
+    const svfloat32_t half = svdup_n_f32(0.5f);
+    svint32_t         iExponent;
+
+    iExponent = svand_s32_x(pg, svreinterpret_s32_f32(value.simdInternal_), exponentMask);
+    iExponent = svsub_s32_x(
+            pg, svreinterpret_s32_u32(svlsr_n_u32_x(pg, svreinterpret_u32_s32(iExponent), 23)), exponentBias);
+    exponent->simdInternal_ = iExponent;
+
+    return { svreinterpret_f32_s32(svorr_s32_x(
+            pg, svand_s32_x(pg, svreinterpret_s32_f32(value.simdInternal_), mantissaMask),
+            svreinterpret_s32_f32(half))) };
+}
+
+template<MathOptimization opt = MathOptimization::Safe>
+static inline SimdFloat gmx_simdcall ldexp(SimdFloat value, SimdFInt32 exponent)
+{
+    svbool_t        pg           = svptrue_b32();
+    const svint32_t exponentBias = svdup_n_s32(127);
+    svint32_t       iExponent    = svadd_s32_x(pg, exponent.simdInternal_, exponentBias);
+
+    if (opt == MathOptimization::Safe)
+    {
+        // Make sure biased argument is not negative
+        iExponent = svmax_n_s32_x(pg, iExponent, 0);
+    }
+
+    iExponent = svlsl_n_s32_x(pg, iExponent, 23);
+
+    return { svmul_f32_x(pg, value.simdInternal_, svreinterpret_f32_s32(iExponent)) };
+}
+
+static inline float gmx_simdcall reduce(SimdFloat a)
+{
+    svbool_t pg = svptrue_b32();
+    return svaddv_f32(pg, a.simdInternal_);
+}
+
+static inline SimdFBool gmx_simdcall operator==(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcmpeq_f32(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFBool gmx_simdcall operator!=(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcmpne_f32(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFBool gmx_simdcall operator<(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcmplt_f32(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFBool gmx_simdcall operator<=(SimdFloat a, SimdFloat b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcmple_f32(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFBool gmx_simdcall testBits(SimdFloat a)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcmpne_n_s32(pg, svreinterpret_s32_f32(a.simdInternal_), 0) };
+}
+
+static inline SimdFBool gmx_simdcall operator&&(SimdFBool a, SimdFBool b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svand_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline SimdFBool gmx_simdcall operator||(SimdFBool a, SimdFBool b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svorr_b_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline bool gmx_simdcall anyTrue(SimdFBool a)
+{
+    svbool_t pg = svptrue_b32();
+    return svptest_any(pg, getMask(a));
+}
+
+static inline bool gmx_simdcall extractFirst(SimdFBool a)
+{
+    svbool_t pg = svptrue_b32();
+    return svptest_first(pg, getMask(a));
+}
+
+static inline SimdFloat gmx_simdcall selectByMask(SimdFloat a, SimdFBool m)
+{
+    return { svsel_f32(getMask(m), a.simdInternal_, svdup_f32(0.0f)) };
+}
+
+static inline SimdFloat gmx_simdcall selectByNotMask(SimdFloat a, SimdFBool m)
+{
+    svbool_t pg = svptrue_b32();
+    return { svsel_f32(sveor_b_z(pg, getMask(m), pg), a.simdInternal_, svdup_f32(0.0f)) };
+}
+
+static inline SimdFloat gmx_simdcall blend(SimdFloat a, SimdFloat b, SimdFBool sel)
+{
+    return { svsel_f32(getMask(sel), b.simdInternal_, a.simdInternal_) };
+}
+
+static inline SimdFInt32 gmx_simdcall operator&(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svand_s32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFInt32 gmx_simdcall andNot(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svbic_s32_x(pg, b.simdInternal_, a.simdInternal_) };
+}
+
+static inline SimdFInt32 gmx_simdcall operator|(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svorr_s32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFInt32 gmx_simdcall operator^(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { sveor_s32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFInt32 gmx_simdcall operator+(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svadd_s32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFInt32 gmx_simdcall operator-(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svsub_s32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFInt32 gmx_simdcall operator*(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svmul_s32_x(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFIBool gmx_simdcall operator==(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcmpeq_s32(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFIBool gmx_simdcall testBits(SimdFInt32 a)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcmpne_n_s32(pg, a.simdInternal_, (int32_t)0) };
+}
+
+static inline SimdFIBool gmx_simdcall operator<(SimdFInt32 a, SimdFInt32 b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcmplt_s32(pg, a.simdInternal_, b.simdInternal_) };
+}
+
+static inline SimdFIBool gmx_simdcall operator&&(SimdFIBool a, SimdFIBool b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svand_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline SimdFIBool gmx_simdcall operator||(SimdFIBool a, SimdFIBool b)
+{
+    svbool_t pg = svptrue_b32();
+    return { svorr_b_z(pg, getMask(a), getMask(b)) };
+}
+
+static inline bool gmx_simdcall anyTrue(SimdFIBool a)
+{
+    svbool_t pg = svptrue_b32();
+    return svptest_any(pg, getMask(a));
+}
+
+static inline SimdFInt32 gmx_simdcall selectByMask(SimdFInt32 a, SimdFIBool m)
+{
+    return { svadd_n_s32_z(getMask(m), a.simdInternal_, 0) };
+}
+
+static inline SimdFInt32 gmx_simdcall selectByNotMask(SimdFInt32 a, SimdFIBool m)
+{
+    svbool_t pg = svptrue_b32();
+    return { svadd_n_s32_z(sveor_b_z(pg, getMask(m), pg), a.simdInternal_, 0.0f) };
+}
+
+static inline SimdFInt32 gmx_simdcall blend(SimdFInt32 a, SimdFInt32 b, SimdFIBool sel)
+{
+    return { svsel_s32(getMask(sel), b.simdInternal_, a.simdInternal_) };
+}
+
+static inline SimdFInt32 gmx_simdcall cvtR2I(SimdFloat a)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcvt_s32_x(pg, svrinta_f32_z(pg, a.simdInternal_)) };
+}
+
+static inline SimdFInt32 gmx_simdcall cvttR2I(SimdFloat a)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcvt_s32_x(pg, a.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall cvtI2R(SimdFInt32 a)
+{
+    svbool_t pg = svptrue_b32();
+    return { svcvt_f32_x(pg, a.simdInternal_) };
+}
+
+static inline SimdFIBool gmx_simdcall cvtB2IB(SimdFBool a)
+{
+    return { getMask(a) };
+}
+
+static inline SimdFBool gmx_simdcall cvtIB2B(SimdFIBool a)
+{
+    return { getMask(a) };
+}
+
+static inline SimdFloat gmx_simdcall round(SimdFloat x)
+{
+    svbool_t pg = svptrue_b32();
+    return { svrinta_f32_x(pg, x.simdInternal_) };
+}
+
+static inline SimdFloat gmx_simdcall trunc(SimdFloat x)
+{
+    return cvtI2R(cvttR2I(x));
+}
+
+} // namespace gmx
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_SIMD_FLOAT_H
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve_util_double.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_util_double.h
new file mode 100644
index 0000000..5cef1a5
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_util_double.h
@@ -0,0 +1,381 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_UTIL_DOUBLE_H
+#define GMX_SIMD_IMPL_ARM_SVE_UTIL_DOUBLE_H
+
+#include "config.h"
+
+#include <cassert>
+#include <cstddef>
+#include <cstdint>
+
+#include <arm_sve.h>
+
+#include "gromacs/utility/basedefinitions.h"
+
+#include "impl_arm_sve_simd_double.h"
+
+
+namespace gmx
+{
+
+template<int align>
+static inline void gmx_simdcall gatherLoadTranspose(const double*      base,
+                                                    const std::int32_t offset[],
+                                                    SimdDouble*        v0,
+                                                    SimdDouble*        v1,
+                                                    SimdDouble*        v2,
+                                                    SimdDouble*        v3)
+{
+    assert(std::size_t(offset) % 16 == 0);
+    assert(std::size_t(base) % 64 == 0);
+    assert(align % 4 == 0);
+
+    svint64_t offsets;
+    svbool_t  pg = svptrue_b64();
+    offsets      = svmul_n_s64_z(
+            pg, svunpklo_s64(svld1_s32(svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH), offset)),
+            align * sizeof(double));
+    v0->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+    offsets           = svadd_n_s64_z(pg, offsets, sizeof(double));
+    v1->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+    offsets           = svadd_n_s64_z(pg, offsets, sizeof(double));
+    v2->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+    offsets           = svadd_n_s64_z(pg, offsets, sizeof(double));
+    v3->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+}
+
+template<int align>
+static inline void gmx_simdcall
+                   gatherLoadBySimdIntTranspose(const double* base, SimdDInt32 offset, SimdDouble* v0, SimdDouble* v1)
+{
+    // Base pointer must be aligned to the smaller of 2 elements and float SIMD width
+    assert(std::size_t(base) % 8 == 0);
+    // align parameter must also be a multiple of the above alignment requirement
+    assert(align % 2 == 0);
+
+    svbool_t  pg = svptrue_b64();
+    svint64_t offsets;
+    offsets           = svmul_n_s64_z(pg, offset.simdInternal_, align * sizeof(double));
+    v0->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+    offsets           = svadd_n_s64_z(pg, offsets, sizeof(double));
+    v1->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+}
+
+template<int align>
+static inline void gmx_simdcall
+                   gatherLoadTranspose(const double* base, const std::int32_t offset[], SimdDouble* v0, SimdDouble* v1)
+{
+    assert(std::size_t(offset) % 64 == 0);
+    assert(std::size_t(base) % 8 == 0);
+    assert(align % 2 == 0);
+
+    SimdDInt32 offsets;
+    svbool_t   pg         = svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH);
+    offsets.simdInternal_ = svunpklo_s64(svld1_s32(pg, offset));
+    gatherLoadBySimdIntTranspose<align>(base, offsets, v0, v1);
+}
+
+static const int c_simdBestPairAlignmentDouble = 2;
+
+template<int align>
+static inline void gmx_simdcall gatherLoadUTranspose(const double*      base,
+                                                     const std::int32_t offset[],
+                                                     SimdDouble*        v0,
+                                                     SimdDouble*        v1,
+                                                     SimdDouble*        v2)
+{
+    assert(std::size_t(offset) % 16 == 0);
+
+    svint64_t offsets;
+    svbool_t  pg = svptrue_b64();
+    offsets      = svmul_n_s64_z(
+            pg, svunpklo_s64(svld1_s32(svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH), offset)),
+            align * sizeof(double));
+    v0->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+    offsets           = svadd_n_s64_z(pg, offsets, sizeof(double));
+    v1->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+    offsets           = svadd_n_s64_z(pg, offsets, sizeof(double));
+    v2->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+}
+
+
+template<int align>
+static inline void gmx_simdcall transposeScatterStoreU(double*            base,
+                                                       const std::int32_t offset[],
+                                                       SimdDouble         v0,
+                                                       SimdDouble         v1,
+                                                       SimdDouble         v2)
+{
+    assert(std::size_t(offset) % 16 == 0);
+
+    svint64_t offsets;
+    svbool_t  pg = SVE_DOUBLE_MASK;
+    offsets      = svmul_n_s64_z(
+            pg, svunpklo_s64(svld1_s32(svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH), offset)),
+            align * sizeof(double));
+    svst1_scatter_s64offset_f64(pg, base, offsets, v0.simdInternal_);
+    offsets = svadd_n_s64_z(pg, offsets, sizeof(double));
+    svst1_scatter_s64offset_f64(pg, base, offsets, v1.simdInternal_);
+    offsets = svadd_n_s64_z(pg, offsets, sizeof(double));
+    svst1_scatter_s64offset_f64(pg, base, offsets, v2.simdInternal_);
+}
+
+
+template<int align>
+static inline void gmx_simdcall
+                   transposeScatterIncrU(double* base, const std::int32_t offset[], SimdDouble v0, SimdDouble v1, SimdDouble v2)
+{
+    assert(std::size_t(offset) % 32 == 0);
+
+    svbool_t                           pg = SVE_DOUBLE_MASK;
+    svfloat64x3_t                      v;
+    alignas(GMX_SIMD_ALIGNMENT) double tvec[3 * GMX_SIMD_DOUBLE_WIDTH];
+    v = svcreate3_f64(v0.simdInternal_, v1.simdInternal_, v2.simdInternal_);
+    svst3_f64(pg, tvec, v);
+    pg = svwhilelt_b64(0, 3);
+    for (int i = 0; i < GMX_SIMD_DOUBLE_WIDTH; i++)
+    {
+        svfloat64_t t1 = svld1_f64(pg, base + align * offset[i]);
+        svfloat64_t t2 = svld1_f64(pg, tvec + 3 * i);
+        svfloat64_t t3 = svadd_f64_z(pg, t1, t2);
+        svst1_f64(pg, base + align * offset[i], t3);
+    }
+}
+
+template<int align>
+static inline void gmx_simdcall
+                   transposeScatterDecrU(double* base, const std::int32_t offset[], SimdDouble v0, SimdDouble v1, SimdDouble v2)
+{
+    assert(std::size_t(offset) % 16 == 0);
+
+    svbool_t                           pg = SVE_DOUBLE_MASK;
+    svfloat64x3_t                      v;
+    alignas(GMX_SIMD_ALIGNMENT) double tvec[3 * GMX_SIMD_DOUBLE_WIDTH];
+    v = svcreate3_f64(v0.simdInternal_, v1.simdInternal_, v2.simdInternal_);
+    svst3_f64(pg, tvec, v);
+    pg = svwhilelt_b64(0, 3);
+    for (int i = 0; i < GMX_SIMD_DOUBLE_WIDTH; i++)
+    {
+        svfloat64_t t1 = svld1_f64(pg, base + align * offset[i]);
+        svfloat64_t t2 = svld1_f64(pg, tvec + 3 * i);
+        svfloat64_t t3 = svsub_f64_z(pg, t1, t2);
+        svst1_f64(pg, base + align * offset[i], t3);
+    }
+}
+
+static inline void gmx_simdcall expandScalarsToTriplets(SimdDouble  scalar,
+                                                        SimdDouble* triplets0,
+                                                        SimdDouble* triplets1,
+                                                        SimdDouble* triplets2)
+{
+    assert(GMX_SIMD_DOUBLE_WIDTH <= 16);
+    uint64_t   ind[48] = { 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,
+                         5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,  9,  9,  10, 10,
+                         10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15 };
+    svbool_t   pg;
+    svuint64_t idx;
+
+    pg                       = SVE_DOUBLE_MASK;
+    idx                      = svld1_u64(pg, ind);
+    triplets0->simdInternal_ = svtbl_f64(scalar.simdInternal_, idx);
+    idx                      = svld1_u64(pg, ind + GMX_SIMD_DOUBLE_WIDTH);
+    triplets1->simdInternal_ = svtbl_f64(scalar.simdInternal_, idx);
+    idx                      = svld1_u64(pg, ind + 2 * GMX_SIMD_DOUBLE_WIDTH);
+    triplets2->simdInternal_ = svtbl_f64(scalar.simdInternal_, idx);
+}
+
+template<int align>
+static inline void gmx_simdcall gatherLoadBySimdIntTranspose(const double* base,
+                                                             SimdDInt32    offset,
+                                                             SimdDouble*   v0,
+                                                             SimdDouble*   v1,
+                                                             SimdDouble*   v2,
+                                                             SimdDouble*   v3)
+{
+    alignas(GMX_SIMD_ALIGNMENT) std::int32_t ioffset[GMX_SIMD_FINT32_WIDTH];
+
+    assert(std::size_t(base) % 16 == 0);
+    assert(align % 4 == 0);
+
+    store(ioffset, offset);
+    gatherLoadTranspose<align>(base, ioffset, v0, v1, v2, v3);
+}
+
+
+template<int align>
+static inline void gmx_simdcall
+                   gatherLoadUBySimdIntTranspose(const double* base, SimdDInt32 offset, SimdDouble* v0, SimdDouble* v1)
+{
+    svbool_t  pg      = SVE_DOUBLE_MASK;
+    svint64_t offsets = svmul_n_s64_z(pg, offset.simdInternal_, align * sizeof(double));
+    v0->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+    offsets           = svadd_n_s64_z(pg, offsets, sizeof(double));
+    v1->simdInternal_ = svld1_gather_s64offset_f64(pg, base, offsets);
+}
+
+static inline double gmx_simdcall
+                     reduceIncr4ReturnSum(double* m, SimdDouble v0, SimdDouble v1, SimdDouble v2, SimdDouble v3)
+{
+    assert(std::size_t(m) % 16 == 0);
+    svbool_t    pg = SVE_DOUBLE_MASK;
+    svfloat64_t _m, _s;
+    double      sum[4];
+    sum[0] = svadda_f64(pg, 0.0, v0.simdInternal_);
+    sum[1] = svadda_f64(pg, 0.0, v1.simdInternal_);
+    sum[2] = svadda_f64(pg, 0.0, v2.simdInternal_);
+    sum[3] = svadda_f64(pg, 0.0, v3.simdInternal_);
+    pg     = svwhilelt_b64(0, 4);
+    _m     = svld1_f64(pg, m);
+    _s     = svld1_f64(pg, sum);
+    svst1_f64(pg, m, svadd_f64_z(pg, _m, _s));
+    return svadda_f64(pg, 0.0, _s);
+}
+
+static inline SimdDouble gmx_simdcall loadDualHsimd(const double* m0, const double* m1)
+{
+    svfloat64_t v0, v1;
+    svbool_t    pg = svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH / 2);
+    v0             = svld1_f64(pg, m0);
+    v1             = svld1_f64(pg, m1);
+    return { svsplice_f64(pg, v0, v1) };
+}
+
+static inline SimdDouble gmx_simdcall loadDuplicateHsimd(const double* m)
+{
+    svfloat64_t v;
+    svbool_t    pg = svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH / 2);
+    v              = svld1_f64(pg, m);
+    return { svsplice_f64(pg, v, v) };
+}
+
+static inline SimdDouble gmx_simdcall loadU1DualHsimd(const double* m)
+{
+    svfloat64_t v0, v1;
+    svbool_t    pg = svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH / 2);
+    v0             = svdup_f64(m[0]);
+    v1             = svdup_f64(m[1]);
+    return { svsplice_f64(pg, v0, v1) };
+}
+
+static inline void gmx_simdcall storeDualHsimd(double* m0, double* m1, SimdDouble a)
+{
+    svbool_t pg = svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH / 2);
+    svst1_f64(pg, m0, a.simdInternal_);
+    pg = sveor_b_z(svptrue_b64(), pg, svptrue_b64());
+    svst1_f64(pg, m1 - GMX_SIMD_DOUBLE_WIDTH / 2, a.simdInternal_);
+}
+
+static inline void gmx_simdcall incrDualHsimd(double* m0, double* m1, SimdDouble a)
+{
+    // Make sure the memory pointer is aligned to half float SIMD width
+    assert(std::size_t(m0) % 32 == 0);
+    assert(std::size_t(m1) % 32 == 0);
+
+    svbool_t    pg = svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH / 2);
+    svfloat64_t v0, v2, v3;
+    v0 = svld1_f64(pg, m0);
+    v2 = svadd_f64_z(pg, v0, a.simdInternal_);
+    svst1_f64(pg, m0, v2);
+    v0 = svld1_f64(pg, m1);
+    v3 = svext_f64(a.simdInternal_, a.simdInternal_, GMX_SIMD_DOUBLE_WIDTH / 2);
+    v2 = svadd_f64_z(pg, v0, v3);
+    svst1_f64(pg, m1, v2);
+}
+
+static inline void gmx_simdcall decrHsimd(double* m, SimdDouble a)
+{
+    // Make sure the memory pointer is aligned to half float SIMD width
+    assert(std::size_t(m) % 32 == 0);
+
+    svbool_t    pg = svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH / 2);
+    svfloat64_t v0, v1, v2, v3;
+    v0 = svld1_f64(pg, m);
+    v1 = svext_f64(a.simdInternal_, a.simdInternal_, GMX_SIMD_DOUBLE_WIDTH / 2);
+    v2 = svadd_f64_z(pg, a.simdInternal_, v1);
+    v3 = svsub_f64_z(pg, v0, v2);
+    svst1_f64(pg, m, v3);
+}
+
+static inline double gmx_simdcall reduceIncr4ReturnSumHsimd(double* m, SimdDouble v0, SimdDouble v1)
+{
+    svbool_t    pg = svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH / 2);
+    svfloat64_t _m, _s;
+    double      sum[4];
+    sum[0] = svadda_f64(pg, 0.0, v0.simdInternal_);
+    sum[2] = svadda_f64(pg, 0.0, v1.simdInternal_);
+    pg     = sveor_b_z(svptrue_b64(), pg, svptrue_b64());
+    sum[1] = svadda_f64(pg, 0.0, v0.simdInternal_);
+    sum[3] = svadda_f64(pg, 0.0, v1.simdInternal_);
+
+    pg = svwhilelt_b64(0, 4);
+    _m = svld1_f64(pg, m);
+    _s = svld1_f64(pg, sum);
+    svst1_f64(pg, m, svadd_f64_z(pg, _m, _s));
+    return svadda_f64(pg, 0.0, _s);
+}
+
+template<int align>
+static inline void gmx_simdcall gatherLoadTransposeHsimd(const double*      base0,
+                                                         const double*      base1,
+                                                         const std::int32_t offset[],
+                                                         SimdDouble*        v0,
+                                                         SimdDouble*        v1)
+{
+    svint64_t   offsets;
+    svbool_t    pg = svwhilelt_b64(0, (int32_t)GMX_SIMD_DOUBLE_WIDTH / 2);
+    svfloat64_t _v0, _v1, tmp;
+    offsets = svmul_n_s64_z(
+            pg, svunpklo(svld1_s32(svwhilelt_b32(0, (int32_t)GMX_SIMD_DINT32_WIDTH / 2), offset)),
+            align * sizeof(double));
+    _v0               = svld1_gather_s64offset_f64(pg, base0, offsets);
+    _v1               = svld1_gather_s64offset_f64(pg, base1, offsets);
+    v0->simdInternal_ = svsplice_f64(pg, _v0, _v1);
+    offsets           = svadd_n_s64_z(pg, offsets, sizeof(double));
+    _v0               = svld1_gather_s64offset_f64(pg, base0, offsets);
+    _v1               = svld1_gather_s64offset_f64(pg, base1, offsets);
+    v1->simdInternal_ = svsplice_f64(pg, _v0, _v1);
+}
+
+} // namespace gmx
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_UTIL_DOUBLE_H
diff --git a/src/gromacs/simd/impl_arm_sve/impl_arm_sve_util_float.h b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_util_float.h
new file mode 100644
index 0000000..82d43cb
--- /dev/null
+++ b/src/gromacs/simd/impl_arm_sve/impl_arm_sve_util_float.h
@@ -0,0 +1,611 @@
+/*
+ * This file is part of the GROMACS molecular simulation package.
+ *
+ * Copyright (c) 2020 Research Organization for Information Science and Technology (RIST).
+ * Copyright (c) 2020, by the GROMACS development team, led by
+ * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
+ * and including many others, as listed in the AUTHORS file in the
+ * top-level source directory and at http://www.gromacs.org.
+ *
+ * GROMACS is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation; either version 2.1
+ * of the License, or (at your option) any later version.
+ *
+ * GROMACS is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with GROMACS; if not, see
+ * http://www.gnu.org/licenses, or write to the Free Software Foundation,
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA.
+ *
+ * If you want to redistribute modifications to GROMACS, please
+ * consider that scientific software is very special. Version
+ * control is crucial - bugs must be traceable. We will be happy to
+ * consider code for inclusion in the official distribution, but
+ * derived work must not be called official GROMACS. Details are found
+ * in the README & COPYING files - if they are missing, get the
+ * official version at http://www.gromacs.org.
+ *
+ * To help us fund GROMACS development, we humbly ask that you cite
+ * the research papers on the package. Check out http://www.gromacs.org.
+ */
+
+/*
+ * armv8+sve support to GROMACS was contributed by the Research Organization for
+ * Information Science and Technology (RIST).
+ */
+
+#ifndef GMX_SIMD_IMPL_ARM_SVE_UTIL_FLOAT_H
+#define GMX_SIMD_IMPL_ARM_SVE_UTIL_FLOAT_H
+
+#include "config.h"
+
+#include <cassert>
+#include <cstddef>
+#include <cstdint>
+
+#include <arm_sve.h>
+
+#include "gromacs/utility/basedefinitions.h"
+
+#include "impl_arm_sve_simd_float.h"
+
+#define SVE_FLOAT_HALF_MASK svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH/2)
+#define SVE_FINT32_HALF_MASK svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH/2)
+
+namespace gmx
+{
+
+template<int align>
+static inline void gmx_simdcall gatherLoadTranspose(const float*       base,
+                                                    const std::int32_t offset[],
+                                                    SimdFloat*         v0,
+                                                    SimdFloat*         v1,
+                                                    SimdFloat*         v2,
+                                                    SimdFloat*         v3)
+{
+    assert(std::size_t(offset) % 16 == 0);
+    assert(std::size_t(base) % 16 == 0);
+    assert(align % 4 == 0);
+
+    svint32_t offsets;
+#if 0
+    svbool_t pg = SVE_FINT32_MASK;
+    offsets = svmul_n_s32_z(pg, svld1_s32(pg, offset), align*4);
+    v0->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+    offsets = svadd_n_s32_z(pg, offsets, 4);
+    v1->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+    offsets = svadd_n_s32_z(pg, offsets, 4);
+    v2->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+    offsets = svadd_n_s32_z(pg, offsets, 4);
+    v3->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+#else
+    svbool_t pg       = SVE_FINT32_MASK;
+    offsets           = svmul_n_s32_z(pg, svld1_s32(pg, offset), align);
+    v0->simdInternal_ = svld1_gather_s32index_f32(pg, base, offsets);
+    offsets           = svadd_n_s32_z(pg, offsets, 1);
+    v1->simdInternal_ = svld1_gather_s32index_f32(pg, base, offsets);
+    offsets           = svadd_n_s32_z(pg, offsets, 1);
+    v2->simdInternal_ = svld1_gather_s32index_f32(pg, base, offsets);
+    offsets           = svadd_n_s32_z(pg, offsets, 1);
+    v3->simdInternal_ = svld1_gather_s32index_f32(pg, base, offsets);
+#endif
+}
+
+template<int align>
+static inline void gmx_simdcall
+                   gatherLoadBySimdIntTranspose(const float* base, SimdFInt32 offset, SimdFloat* v0, SimdFloat* v1)
+{
+    // Base pointer must be aligned to the smaller of 2 elements and float SIMD width
+    assert(std::size_t(base) % 8 == 0);
+    // align parameter must also be a multiple of the above alignment requirement
+    assert(align % 2 == 0);
+
+    if (align < 2)
+    {
+        svbool_t  pg = SVE_FINT32_MASK;
+        svint32_t offsets;
+        offsets           = svmul_n_s32_z(pg, offset.simdInternal_, align * 4);
+        v0->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+        offsets           = svadd_n_s32_z(pg, offsets, 4);
+        v1->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+#if 1
+    }
+    else if (2 == align)
+    {
+        assert(0);
+        svbool_t    pg    = SVE_FLOAT_MASK;
+        svfloat32_t t0    = svreinterpret_f32_u64(svld1_gather_s64index_u64(
+                svunpklo_b(pg), (uint64_t*)base, svunpklo_s64(offset.simdInternal_)));
+        svfloat32_t t1    = svreinterpret_f32_u64(svld1_gather_s64index_u64(
+                svunpkhi_b(pg), (uint64_t*)base, svunpkhi_s64(offset.simdInternal_)));
+        v0->simdInternal_ = svuzp1(t0, t1);
+        v1->simdInternal_ = svuzp2(t0, t1);
+#endif
+    }
+    else
+    {
+        svbool_t    pg      = SVE_FLOAT_MASK;
+        svint32_t   offsets = svmul_n_s32_z(pg, offset.simdInternal_, align / 2);
+        svfloat32_t t0      = svreinterpret_f32_u64(
+                svld1_gather_s64index_u64(svunpklo_b(pg), (uint64_t*)base, svunpklo_s64(offsets)));
+        svfloat32_t t1 = svreinterpret_f32_u64(
+                svld1_gather_s64index_u64(svunpkhi_b(pg), (uint64_t*)base, svunpkhi_s64(offsets)));
+        v0->simdInternal_ = svuzp1(t0, t1);
+        v1->simdInternal_ = svuzp2(t0, t1);
+    }
+}
+
+template<int align>
+static inline void gmx_simdcall
+                   gatherLoadTranspose(const float* base, const std::int32_t offset[], SimdFloat* v0, SimdFloat* v1)
+{
+    assert(std::size_t(offset) % 64 == 0);
+    assert(std::size_t(base) % 8 == 0);
+    assert(align % 2 == 0);
+
+    SimdFInt32 offsets;
+    svbool_t   pg         = SVE_FINT32_MASK;
+    offsets.simdInternal_ = svld1(pg, offset);
+    gatherLoadBySimdIntTranspose<align>(base, offsets, v0, v1);
+}
+
+static const int c_simdBestPairAlignmentFloat = 2;
+
+template<int align>
+static inline void gmx_simdcall gatherLoadUTranspose(const float*       base,
+                                                     const std::int32_t offset[],
+                                                     SimdFloat*         v0,
+                                                     SimdFloat*         v1,
+                                                     SimdFloat*         v2)
+{
+    assert(std::size_t(offset) % 16 == 0);
+
+    svint32_t offsets;
+    svbool_t  pg      = SVE_FINT32_MASK;
+    offsets           = svmul_n_s32_z(pg, svld1_s32(pg, offset), align * 4);
+    v0->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+    offsets           = svadd_n_s32_z(pg, offsets, 4);
+    v1->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+    offsets           = svadd_n_s32_z(pg, offsets, 4);
+    v2->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+}
+
+
+template<int align>
+static inline void gmx_simdcall
+                   transposeScatterStoreU(float* base, const std::int32_t offset[], SimdFloat v0, SimdFloat v1, SimdFloat v2)
+{
+    assert(std::size_t(offset) % 16 == 0);
+
+    svint32_t offsets;
+    svbool_t  pg = SVE_FINT32_MASK;
+    offsets      = svmul_n_s32_z(pg, svld1_s32(pg, offset), align * 4);
+    svst1_scatter_s32offset_f32(pg, base, offsets, v0.simdInternal_);
+    offsets = svadd_n_s32_z(pg, offsets, 4);
+    svst1_scatter_s32offset_f32(pg, base, offsets, v1.simdInternal_);
+    offsets = svadd_n_s32_z(pg, offsets, 4);
+    svst1_scatter_s32offset_f32(pg, base, offsets, v2.simdInternal_);
+}
+
+
+template<int align>
+static inline void gmx_simdcall
+                   transposeScatterIncrU(float* base, const std::int32_t offset[], SimdFloat v0, SimdFloat v1, SimdFloat v2)
+{
+    assert(std::size_t(offset) % 64 == 0);
+
+    svbool_t                          pg = SVE_FINT32_MASK;
+    svfloat32x3_t                     v;
+    alignas(GMX_SIMD_ALIGNMENT) float tvec[3 * GMX_SIMD_FLOAT_WIDTH];
+    v = svcreate3_f32(v0.simdInternal_, v1.simdInternal_, v2.simdInternal_);
+    svst3_f32(pg, tvec, v);
+    pg = svwhilelt_b32(0, 3);
+    for (int i = 0; i < GMX_SIMD_FLOAT_WIDTH; i++)
+    {
+        svfloat32_t t1 = svld1_f32(pg, base + align * offset[i]);
+        svfloat32_t t2 = svld1_f32(pg, tvec + 3 * i);
+        svfloat32_t t3 = svadd_f32_z(pg, t1, t2);
+        svst1_f32(pg, base + align * offset[i], t3);
+    }
+}
+
+template<int align>
+static inline void gmx_simdcall
+                   transposeScatterDecrU(float* base, const std::int32_t offset[], SimdFloat v0, SimdFloat v1, SimdFloat v2)
+{
+    assert(std::size_t(offset) % 16 == 0);
+
+    svbool_t                          pg = SVE_FLOAT_MASK;
+    svfloat32x3_t                     v;
+    alignas(GMX_SIMD_ALIGNMENT) float tvec[3 * GMX_SIMD_FLOAT_WIDTH];
+    v = svcreate3_f32(v0.simdInternal_, v1.simdInternal_, v2.simdInternal_);
+    svst3_f32(pg, tvec, v);
+    pg = svwhilelt_b32(0, 3);
+    for (int i = 0; i < GMX_SIMD_FLOAT_WIDTH; i++)
+    {
+        svfloat32_t t1 = svld1_f32(pg, base + align * offset[i]);
+        svfloat32_t t2 = svld1_f32(pg, tvec + 3 * i);
+        svfloat32_t t3 = svsub_f32_z(pg, t1, t2);
+        svst1_f32(pg, base + align * offset[i], t3);
+    }
+}
+
+static inline void gmx_simdcall expandScalarsToTriplets(SimdFloat  scalar,
+                                                        SimdFloat* triplets0,
+                                                        SimdFloat* triplets1,
+                                                        SimdFloat* triplets2)
+{
+    assert(GMX_SIMD_FLOAT_WIDTH <= 16);
+    uint32_t   ind[48] = { 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,
+                         5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,  9,  9,  10, 10,
+                         10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15 };
+    svbool_t   pg;
+    svuint32_t idx;
+
+    pg                       = SVE_FLOAT_MASK;
+    idx                      = svld1_u32(pg, ind);
+    triplets0->simdInternal_ = svtbl_f32(scalar.simdInternal_, idx);
+    idx                      = svld1_u32(pg, ind + GMX_SIMD_FLOAT_WIDTH);
+    triplets1->simdInternal_ = svtbl_f32(scalar.simdInternal_, idx);
+    idx                      = svld1_u32(pg, ind + 2 * GMX_SIMD_FLOAT_WIDTH);
+    triplets2->simdInternal_ = svtbl_f32(scalar.simdInternal_, idx);
+}
+
+template<int align>
+static inline void gmx_simdcall gatherLoadBySimdIntTranspose(const float* base,
+                                                             SimdFInt32   offset,
+                                                             SimdFloat*   v0,
+                                                             SimdFloat*   v1,
+                                                             SimdFloat*   v2,
+                                                             SimdFloat*   v3)
+{
+    alignas(GMX_SIMD_ALIGNMENT) std::int32_t ioffset[GMX_SIMD_FINT32_WIDTH];
+
+    assert(std::size_t(base) % 16 == 0);
+    assert(align % 4 == 0);
+
+    store(ioffset, offset);
+    gatherLoadTranspose<align>(base, ioffset, v0, v1, v2, v3);
+}
+
+
+template<int align>
+static inline void gmx_simdcall
+                   gatherLoadUBySimdIntTranspose(const float* base, SimdFInt32 offset, SimdFloat* v0, SimdFloat* v1)
+{
+    svbool_t  pg      = SVE_FLOAT_MASK;
+    svint32_t offsets = svmul_n_s32_z(pg, offset.simdInternal_, align * 4);
+    v0->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+    offsets           = svadd_n_s32_z(pg, offsets, 4);
+    v1->simdInternal_ = svld1_gather_s32offset_f32(pg, base, offsets);
+}
+
+static inline float gmx_simdcall reduceIncr4ReturnSum(float* m, SimdFloat v0, SimdFloat v1, SimdFloat v2, SimdFloat v3)
+{
+    assert(std::size_t(m) % 16 == 0);
+    svbool_t    pg = SVE_FLOAT_MASK;
+    svfloat32_t _m, _s;
+    float32_t   sum[4];
+    sum[0] = svadda_f32(pg, 0.0f, v0.simdInternal_);
+    sum[1] = svadda_f32(pg, 0.0f, v1.simdInternal_);
+    sum[2] = svadda_f32(pg, 0.0f, v2.simdInternal_);
+    sum[3] = svadda_f32(pg, 0.0f, v3.simdInternal_);
+    pg     = svwhilelt_b32(0, 4);
+    _m     = svld1_f32(pg, m);
+    _s     = svld1_f32(pg, sum);
+    svst1_f32(pg, m, svadd_f32_z(pg, _m, _s));
+    return svadda_f32(pg, 0.0f, _s);
+}
+
+static inline SimdFloat gmx_simdcall loadDualHsimd(const float* m0, const float* m1)
+{
+    svfloat32_t v0, v1;
+    svbool_t    pg = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    v0             = svld1_f32(pg, m0);
+    v1             = svld1_f32(pg, m1);
+    return { svsplice_f32(pg, v0, v1) };
+}
+
+static inline SimdFloat gmx_simdcall loadDuplicateHsimd(const float* m)
+{
+    svfloat32_t v;
+    svbool_t    pg = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    v              = svld1_f32(pg, m);
+    return { svsplice_f32(pg, v, v) };
+}
+
+template<int stride>
+static inline void gmx_simdcall loadDuplicate2Hsimd(const float* m, SimdFloat* r0, SimdFloat* r1)
+{
+    if (stride == GMX_SIMD_FLOAT_WIDTH / 2)
+    {
+        svfloat32_t v;
+        svbool_t    pg    = SVE_FLOAT_MASK;
+        svbool_t    pg2   = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+        v                 = svld1_f32(pg, m);
+        r0->simdInternal_ = svsplice_f32(pg2, v, v);
+        v                 = svext_f32(v, v, GMX_SIMD_FLOAT_WIDTH / 2);
+        r1->simdInternal_ = svsplice_f32(pg2, v, v);
+    }
+    else
+    {
+        *r0 = loadDuplicateHsimd(m);
+        *r1 = loadDuplicateHsimd(m + stride);
+    }
+}
+
+template<int stride>
+static inline void gmx_simdcall loadDuplicate3Hsimd(const float* m, SimdFloat* r0, SimdFloat* r1, SimdFloat* r2)
+{
+    if (stride == GMX_SIMD_FLOAT_WIDTH / 2)
+    {
+        svfloat32_t v;
+        svbool_t    pg    = SVE_FLOAT_MASK;
+        svbool_t    pg2   = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+        v                 = svld1_f32(pg, m);
+        r0->simdInternal_ = svsplice_f32(pg2, v, v);
+        v                 = svext_f32(v, v, GMX_SIMD_FLOAT_WIDTH / 2);
+        r1->simdInternal_ = svsplice_f32(pg2, v, v);
+        v                 = svld1_f32(pg2, m + 2 * stride);
+        r2->simdInternal_ = svsplice_f32(pg2, v, v);
+    }
+    else
+    {
+        *r0 = loadDuplicateHsimd(m);
+        *r1 = loadDuplicateHsimd(m + stride);
+        *r2 = loadDuplicateHsimd(m + 2 * stride);
+    }
+}
+
+static inline SimdFloat gmx_simdcall loadU1DualHsimd(const float* m)
+{
+    svfloat32_t v0, v1;
+    svbool_t    pg = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    v0             = svdup_f32(m[0]);
+    v1             = svdup_f32(m[1]);
+    return { svsplice_f32(pg, v0, v1) };
+}
+
+static inline void gmx_simdcall loadU12DualHsimd(const float* m, SimdFloat* v0, SimdFloat* v1)
+{
+    svfloat32_t v;
+    svbool_t    pg = svwhilelt_b32(0, 4);
+    v              = svld1_f32(pg, m);
+    v              = svzip1_f32(v, v);
+    v              = svzip1_f32(v, v);
+    *v0            = svzip1_f32(v, v);
+    *v1            = svzip2_f32(v, v);
+}
+
+template<int stride>
+static inline void gmx_simdcall
+                   loadU14DualHsimd(const float* m, SimdFloat* v0, SimdFloat* v1, SimdFloat* v2, SimdFloat* v3)
+{
+    if (4 == stride)
+    {
+        svfloat32_t v, w;
+        svbool_t    pg = svwhilelt_b32(0, 8);
+        v              = svld1_f32(pg, m);
+        v              = svzip1_f32(v, v);
+        w              = svzip2_f32(v, v);
+        v              = svzip1_f32(v, v);
+        *v0            = svzip1_f32(v, v);
+        *v1            = svzip2_f32(v, v);
+        *v2            = svzip1_f32(w, w);
+        *v3            = svzip2_f32(w, w);
+    }
+    else
+    {
+        loadU12DualHsimd(m, v0, v1);
+        loadU12DualHsimd(m + stride, v2, v3);
+    }
+}
+
+static inline void gmx_simdcall storeDualHsimd(float* m0, float* m1, SimdFloat a)
+{
+    svbool_t pg = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    svst1_f32(pg, m0, a.simdInternal_);
+    svst1_f32(pg, m1, svext_f32(a.simdInternal_, a.simdInternal_, GMX_SIMD_FLOAT_WIDTH / 2));
+}
+
+static inline void gmx_simdcall incrDualHsimd(float* m0, float* m1, SimdFloat a)
+{
+    // Make sure the memory pointer is aligned to half float SIMD width
+    assert(std::size_t(m0) % (GMX_SIMD_FLOAT_WIDTH * sizeof(float) / 2) == 0);
+    assert(std::size_t(m1) % (GMX_SIMD_FLOAT_WIDTH * sizeof(float) / 2) == 0);
+
+    svbool_t    pg = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    svfloat32_t v0, v2, v3;
+    v0 = svld1_f32(pg, m0);
+    v2 = svadd_f32_z(pg, v0, a.simdInternal_);
+    svst1_f32(pg, m0, v2);
+    v0 = svld1_f32(pg, m1);
+    v3 = svext_f32(a.simdInternal_, a.simdInternal_, GMX_SIMD_FLOAT_WIDTH / 2);
+    v2 = svadd_f32_z(pg, v0, v3);
+    svst1_f32(pg, m1, v2);
+}
+
+static inline void gmx_simdcall decrHsimd(float* m, SimdFloat a)
+{
+    // Make sure the memory pointer is aligned to half float SIMD width
+    assert(std::size_t(m) % (GMX_SIMD_FLOAT_WIDTH * sizeof(float) / 2) == 0);
+
+    svbool_t    pg = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    svfloat32_t v0, v1, v2, v3;
+    v0 = svld1_f32(pg, m);
+    v1 = svext_f32(a.simdInternal_, a.simdInternal_, GMX_SIMD_FLOAT_WIDTH / 2);
+    v2 = svadd_f32_z(pg, a.simdInternal_, v1);
+    v3 = svsub_f32_z(pg, v0, v2);
+    svst1_f32(pg, m, v3);
+}
+
+static uint32_t indices[16] = { 0, 2, 4, 6, 8, 10, 12, 14, 1, 3, 5, 7, 9, 11, 13, 15 };
+
+template<int stride>
+static inline void gmx_simdcall decr3Hsimd(float* m, SimdFloat a, SimdFloat b, SimdFloat c)
+{
+    // Make sure the memory pointer is aligned to half float SIMD width
+    assert(std::size_t(m) % (GMX_SIMD_FLOAT_WIDTH * sizeof(float) / 2) == 0);
+
+    if (stride == GMX_SIMD_FLOAT_WIDTH / 2)
+    {
+        svbool_t pg = SVE_FLOAT_MASK;
+#if 0
+        svbool_t pg2 = svwhilelt_b32(0,GMX_SIMD_FLOAT_WIDTH/2);
+        svfloat32_t v0, v1, v2, v3;
+        v0 = svld1_f32(pg, m);
+        v1 = svsplice_f32(pg2, a.simdInternal_, b.simdInternal_);
+        v0 = svsub_f32_z(pg, v0, v1);
+        v2 = svext_f32(b.simdInternal_, b.simdInternal_, GMX_SIMD_FLOAT_WIDTH/2);
+        v1 = svext_f32(a.simdInternal_, v2, GMX_SIMD_FLOAT_WIDTH/2);
+        v0 = svsub_f32_z(pg, v0, v1);
+        svst1_f32(pg, m, v0);
+#else
+        svfloat32_t v0, v1, v2;
+        svuint32_t  idx;
+        v0  = svld1_f32(pg, m);
+        v1  = svzip1_f32(a.simdInternal_, b.simdInternal_);
+        v2  = svzip2_f32(a.simdInternal_, b.simdInternal_);
+        v1  = svadd_f32_z(pg, v1, v2);
+        idx = svld1_u32(pg, indices);
+        v1  = svtbl_f32(v1, idx);
+        v0  = svsub_f32_z(pg, v0, v1);
+        svst1_f32(pg, m, v0);
+#endif
+        decrHsimd(m + 2 * stride, c);
+    }
+    else
+    {
+        decrHsimd(m, a);
+        decrHsimd(m + stride, b);
+        decrHsimd(m + 2 * stride, c);
+    }
+}
+
+static inline float gmx_simdcall reduceIncr4ReturnSumHsimd(float* m, SimdFloat v0, SimdFloat v1)
+{
+    svbool_t    pg  = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    svbool_t    pg2 = sveor_b_z(svptrue_b32(), pg, svptrue_b32());
+    svfloat32_t _m, _s;
+
+    _s = svdup_f32(0.0f);
+    _s = svinsr_n_f32(_s, svaddv_f32(pg2, v1.simdInternal_));
+    _s = svinsr_n_f32(_s, svaddv_f32(pg, v1.simdInternal_));
+    _s = svinsr_n_f32(_s, svaddv_f32(pg2, v0.simdInternal_));
+    _s = svinsr_n_f32(_s, svaddv_f32(pg, v0.simdInternal_));
+
+    pg = svwhilelt_b32(0, 4);
+    _m = svld1_f32(pg, m);
+    svst1_f32(pg, m, svadd_f32_z(pg, _m, _s));
+    return svaddv_f32(pg, _s);
+}
+
+static inline void gmx_simdcall reduceIncr4Hsimd(float* m, SimdFloat v0, SimdFloat v1)
+{
+    svbool_t    pg  = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    svbool_t    pg2 = sveor_b_z(svptrue_b32(), pg, svptrue_b32());
+    svfloat32_t _m, _s;
+
+    _s = svinsr_n_f32(_s, svaddv_f32(pg2, v1.simdInternal_));
+    _s = svinsr_n_f32(_s, svaddv_f32(pg, v1.simdInternal_));
+    _s = svinsr_n_f32(_s, svaddv_f32(pg2, v0.simdInternal_));
+    _s = svinsr_n_f32(_s, svaddv_f32(pg, v0.simdInternal_));
+
+    pg = svwhilelt_b32(0, 4);
+    _m = svld1_f32(pg, m);
+    svst1_f32(pg, m, svadd_f32_z(pg, _m, _s));
+}
+
+template<int align>
+static inline void gmx_simdcall gatherLoadTransposeHsimd(const float*       base0,
+                                                         const float*       base1,
+                                                         const std::int32_t offset[],
+                                                         SimdFloat*         v0,
+                                                         SimdFloat*         v1)
+{
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    svint32_t   offsets;
+    svbool_t    pg = svwhilelt_b32(0, GMX_SIMD_FLOAT_WIDTH / 2);
+    svfloat32_t _v0, _v1;
+    offsets           = svmul_n_s32_z(pg, svld1_s32(pg, offset), align * 4);
+    _v0               = svld1_gather_s32offset_f32(pg, base0, offsets);
+    _v1               = svld1_gather_s32offset_f32(pg, base1, offsets);
+    v0->simdInternal_ = svsplice_f32(pg, _v0, _v1);
+    offsets           = svadd_n_s32_z(pg, offsets, 4);
+    _v0               = svld1_gather_s32offset_f32(pg, base0, offsets);
+    _v1               = svld1_gather_s32offset_f32(pg, base1, offsets);
+    v1->simdInternal_ = svsplice_f32(pg, _v0, _v1);
+#else
+    if (2 == align)
+        assert(0);
+    svint64_t offsets = svunpklo_s64(svld1_s32(SVE_FINT32_MASK, offset));
+    offsets           = svmul_n_s64_z(svptrue_b64(), offsets, align * 4);
+    svfloat32_t _v0, _v1;
+    _v0 = svreinterpret_f32_f64(svld1_gather_s64offset_f64(SVE_DOUBLE_MASK, (double*)base0, offsets));
+    _v1 = svreinterpret_f32_f64(svld1_gather_s64offset_f64(SVE_DOUBLE_MASK, (double*)base1, offsets));
+    *v0                 = svuzp1(_v0, _v1);
+    *v1                 = svuzp2(_v0, _v1);
+#endif
+}
+
+template<int align>
+static inline void gmx_simdcall gatherLoadTranspose2Hsimd(const float*       base0,
+                                                          const float*       base1,
+                                                          const float*       base2,
+                                                          const float*       base3,
+                                                          const std::int32_t offset[],
+                                                          SimdFloat*         v0,
+                                                          SimdFloat*         v1,
+                                                          SimdFloat*         v2,
+                                                          SimdFloat*         v3)
+{
+#if !GMX_SIMD_ARM_SVE_FULL_LENGTH
+    svint32_t   offsets;
+    svbool_t    pg = SVE_FLOAT_HALF_MASK;
+    svfloat32_t _v0, _v1;
+    offsets           = svmul_n_s32_z(pg, svld1_s32(pg, offset), align * 4);
+    _v0               = svld1_gather_s32offset_f32(pg, base0, offsets);
+    _v1               = svld1_gather_s32offset_f32(pg, base1, offsets);
+    v0->simdInternal_ = svsplice_f32(pg, _v0, _v1);
+    offsets           = svadd_n_s32_z(pg, offsets, 4);
+    _v0               = svld1_gather_s32offset_f32(pg, base0, offsets);
+    _v1               = svld1_gather_s32offset_f32(pg, base1, offsets);
+    v1->simdInternal_ = svsplice_f32(pg, _v0, _v1);
+#else
+    svint64_t   offsets = svunpklo_s64(svld1_s32(SVE_FINT32_HALF_MASK, offset));
+    svfloat32_t _v0, _v1;
+    if (2 == align)
+    {
+        _v0 = svreinterpret_f32_f64(svld1_gather_s64index_f64(SVE_DOUBLE_MASK, (double*)base0, offsets));
+        _v1 = svreinterpret_f32_f64(svld1_gather_s64index_f64(SVE_DOUBLE_MASK, (double*)base1, offsets));
+    }
+    else
+    {
+        offsets = svmul_n_s64_z(svptrue_b64(), offsets, align * 4);
+        _v0 = svreinterpret_f32_f64(svld1_gather_s64offset_f64(SVE_DOUBLE_MASK, (double*)base0, offsets));
+        _v1 = svreinterpret_f32_f64(svld1_gather_s64offset_f64(SVE_DOUBLE_MASK, (double*)base1, offsets));
+    }
+    *v0 = svuzp1(_v0, _v1);
+    *v1 = svuzp2(_v0, _v1);
+    if (2 == align)
+    {
+        _v0 = svreinterpret_f32_f64(svld1_gather_s64index_f64(SVE_DOUBLE_MASK, (double*)base2, offsets));
+        _v1 = svreinterpret_f32_f64(svld1_gather_s64index_f64(SVE_DOUBLE_MASK, (double*)base3, offsets));
+    }
+    else
+    {
+        _v0 = svreinterpret_f32_f64(svld1_gather_s64offset_f64(SVE_DOUBLE_MASK, (double*)base2, offsets));
+        _v1 = svreinterpret_f32_f64(svld1_gather_s64offset_f64(SVE_DOUBLE_MASK, (double*)base3, offsets));
+    }
+    *v2 = svuzp1(_v0, _v1);
+    *v3 = svuzp2(_v0, _v1);
+#endif
+}
+} // namespace gmx
+
+#endif // GMX_SIMD_IMPL_ARM_SVE_UTIL_FLOAT_H
diff --git a/src/gromacs/simd/simd.h b/src/gromacs/simd/simd.h
index bd9b678..6598e32 100644
--- a/src/gromacs/simd/simd.h
+++ b/src/gromacs/simd/simd.h
@@ -151,6 +151,8 @@ struct SimdDInt32Tag
 #    include "impl_arm_neon/impl_arm_neon.h"
 #elif GMX_SIMD_ARM_NEON_ASIMD
 #    include "impl_arm_neon_asimd/impl_arm_neon_asimd.h"
+#elif GMX_SIMD_ARM_SVE
+#    include "impl_arm_sve/impl_arm_sve.h"
 #elif GMX_SIMD_IBM_VMX
 #    include "impl_ibm_vmx/impl_ibm_vmx.h"
 #elif GMX_SIMD_IBM_VSX
diff --git a/src/gromacs/simd/support.cpp b/src/gromacs/simd/support.cpp
index 7512e0e..08506b2 100644
--- a/src/gromacs/simd/support.cpp
+++ b/src/gromacs/simd/support.cpp
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2015,2016,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2015,2016,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -57,6 +57,8 @@
 #include "gromacs/hardware/cpuinfo.h"
 #include "gromacs/hardware/identifyavx512fmaunits.h"
 #include "gromacs/utility/stringutil.h"
+#include "gromacs/simd/simd.h"
+#include "gromacs/utility/fatalerror.h"
 
 namespace gmx
 {
@@ -80,6 +82,7 @@ const std::string& simdString(SimdType s)
         { SimdType::X86_Mic, "X86_MIC" },
         { SimdType::Arm_Neon, "ARM_NEON" },
         { SimdType::Arm_NeonAsimd, "ARM_NEON_ASIMD" },
+        { SimdType::Arm_Sve, "ARM_SVE" },
         { SimdType::Ibm_Vmx, "IBM_VMX" },
         { SimdType::Ibm_Vsx, "IBM_VSX" },
         { SimdType::Fujitsu_HpcAce, "Fujitsu HPC-ACE" }
@@ -179,7 +182,11 @@ SimdType simdSuggested(const CpuInfo& c)
 
                 break;
             case CpuInfo::Vendor::Arm:
-                if (c.feature(CpuInfo::Feature::Arm_NeonAsimd))
+                if (c.feature(CpuInfo::Feature::Arm_Sve))
+                {
+                    suggested = SimdType::Arm_Sve;
+                }
+                else if (c.feature(CpuInfo::Feature::Arm_NeonAsimd))
                 {
                     suggested = SimdType::Arm_NeonAsimd;
                 }
@@ -234,6 +241,8 @@ SimdType simdCompiled()
     return SimdType::Arm_Neon;
 #elif GMX_SIMD_ARM_NEON_ASIMD
     return SimdType::Arm_NeonAsimd;
+#elif GMX_SIMD_ARM_SVE
+    return SimdType::Arm_Sve;
 #elif GMX_SIMD_IBM_VMX
     return SimdType::Ibm_Vmx;
 #elif GMX_SIMD_IBM_VSX
@@ -319,6 +328,38 @@ bool simdCheck(gmx::SimdType wanted, FILE* log, bool warnToStdErr)
         warnMsg = wrapper.wrapToString(formatString(
                 "Compiled SIMD: %s, but for this host/run %s might be better (see log).",
                 simdString(compiled).c_str(), simdString(wanted).c_str()));
+#if GMX_SIMD_ARM_SVE
+    }
+    else if ((compiled == SimdType::Arm_Sve) && (svcntw() != GMX_SIMD_FLOAT_WIDTH))
+    {
+#    ifndef GMX_SIMD_ARM_SVE_FULL_LENGTH
+        if (svcntw() > GMX_SIMD_FLOAT_WIDTH)
+        {
+            logMsg  = wrapper.wrapToString(formatString(
+                    "Longuest SVE length requested by all nodes in run: %d\n"
+                    "SVE length selected at compile time:               %ld\n"
+                    "This program was compiled for different hardware than you are running on, "
+                    "which could influence performance.",
+                    GMX_SIMD_FLOAT_WIDTH * 32, svcntw() * 32));
+            warnMsg = wrapper.wrapToString(formatString(
+                    "Compiled SVE Length: %d, but for this host/run %ld might be better (see log).",
+                    GMX_SIMD_FLOAT_WIDTH * 32, svcntw() * 32));
+        }
+        else
+#    endif
+        {
+            logMsg  = wrapper.wrapToString(formatString(
+                    "Longuest SVE length requested by all nodes in run: %d\n"
+                    "SVE length selected at compile time:               %ld\n"
+                    "This program was compiled for different hardware than you are running on, "
+                    "which will lead to incorrect behavior.\n"
+                    "Aborting",
+                    GMX_SIMD_FLOAT_WIDTH * 32, svcntw() * 32));
+            warnMsg = wrapper.wrapToString(formatString(
+                    "Compiled SVE Length: %d, but for this process requires %ld (see log).",
+                    GMX_SIMD_FLOAT_WIDTH * 32, svcntw() * 32));
+        }
+#endif
     }
 
     if (!logMsg.empty() && log != nullptr)
@@ -329,6 +370,16 @@ bool simdCheck(gmx::SimdType wanted, FILE* log, bool warnToStdErr)
     {
         fprintf(stderr, "%s\n", warnMsg.c_str());
     }
+#if GMX_SIMD_ARM_SVE
+    if ((compiled == SimdType::Arm_Sve) && (svcntw() != GMX_SIMD_FLOAT_WIDTH)
+#    ifndef GMX_SIMD_ARM_SVE_FULL_LENGTH
+        && (svcntw() < GMX_SIMD_FLOAT_WIDTH)
+#    endif
+    )
+    {
+        gmx_exit_on_fatal_error(ExitType_Abort, 1);
+    }
+#endif
 
     return (wanted == compiled);
 }
diff --git a/src/gromacs/simd/support.h b/src/gromacs/simd/support.h
index 1fd8916..2e10812 100644
--- a/src/gromacs/simd/support.h
+++ b/src/gromacs/simd/support.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2015,2016,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2015,2016,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -70,6 +70,7 @@ enum class SimdType
     X86_Mic,       //!< Knight's corner
     Arm_Neon,      //!< 32-bit ARM NEON
     Arm_NeonAsimd, //!< 64-bit ARM AArch64 Advanced SIMD
+    Arm_Sve,       //!< ARM Scalable Vector Extensions
     Ibm_Vmx,       //!< IBM VMX SIMD (Altivec on Power6 and later)
     Ibm_Vsx,       //!< IBM VSX SIMD (Power7 and later)
     Fujitsu_HpcAce //!< Fujitsu K-computer
-- 
1.8.3.1

From 01f12cdedc6c7205686a212acf9d7c6c6e3c7da0 Mon Sep 17 00:00:00 2001
From: Gilles Gouaillardet <gilles@rist.or.jp>
Date: Tue, 26 May 2020 23:59:20 +0900
Subject: [PATCH 05/32] simd/impl_none: add missing macros

add macros for GMX_SIMD_HAVE_HSIMD_UTIL_{FLOAT,DOUBLE}

(cherry picked from commit 9a68f6f5b1fafb332e7c0fe1ac1197cf802af015)
---
 src/gromacs/simd/impl_none/impl_none.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/src/gromacs/simd/impl_none/impl_none.h b/src/gromacs/simd/impl_none/impl_none.h
index f98de3b..f3ad5c7 100644
--- a/src/gromacs/simd/impl_none/impl_none.h
+++ b/src/gromacs/simd/impl_none/impl_none.h
@@ -52,6 +52,8 @@
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 0
 #define GMX_SIMD4_HAVE_FLOAT 0
 #define GMX_SIMD4_HAVE_DOUBLE 0
+#define GMX_SIMD_HAVE_HSIMD_UTIL_FLOAT 0
+#define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0
 
 #undef GMX_SIMD_FLOAT_WIDTH
 #undef GMX_SIMD_DOUBLE_WIDTH
-- 
1.8.3.1

From 98d2d8bf01e3025f609bde96d5136088e1502507 Mon Sep 17 00:00:00 2001
From: Gilles Gouaillardet <gilles@rist.or.jp>
Date: Thu, 4 Jun 2020 12:35:13 +0900
Subject: [PATCH 06/32] Add GMX_SIMD_HAVE_REAL_ARRAY macro

With upcoming scalable vectors, it might not always be possible to
simply declare an array of registers (e.g. SimdReal foo[]).
This can be avoided by setting the GMX_SIMD_HAVE_FLOAT_ARRAY and/or
GMX_SIMD_HAVE_DOUBLE_ARRAY macros to zero.

(cherry picked from commit f697b3ed2050e2609a6fa781f415706dd9012b23)
---
 src/gromacs/listed_forces/pairs.cpp                                | 2 +-
 src/gromacs/mdlib/settle.cpp                                       | 2 +-
 src/gromacs/pbcutil/pbc_simd.h                                     | 7 +++++--
 src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h         | 4 +++-
 .../simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h     | 4 +++-
 src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h           | 4 +++-
 src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h           | 6 +++++-
 src/gromacs/simd/impl_none/impl_none.h                             | 4 +++-
 src/gromacs/simd/impl_reference/impl_reference_definitions.h       | 6 ++++++
 src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h | 4 +++-
 src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h | 4 +++-
 .../simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h   | 2 ++
 src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h   | 4 +++-
 src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h   | 2 ++
 .../simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h   | 2 ++
 src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h           | 4 +++-
 src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h         | 4 +++-
 src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h     | 4 +++-
 src/gromacs/simd/simd.h                                            | 7 +++++++
 19 files changed, 61 insertions(+), 15 deletions(-)

diff --git a/src/gromacs/listed_forces/pairs.cpp b/src/gromacs/listed_forces/pairs.cpp
index d56a6aa..80eb366 100644
--- a/src/gromacs/listed_forces/pairs.cpp
+++ b/src/gromacs/listed_forces/pairs.cpp
@@ -710,7 +710,7 @@ void do_pairs(int                      ftype,
          * and sum the virial for the shifts. But we should do this
          * at once for the angles and dihedrals as well.
          */
-#if GMX_SIMD_HAVE_REAL
+#if GMX_SIMD_HAVE_REAL_ARRAY
         if (fr->use_simd_kernels)
         {
             alignas(GMX_SIMD_ALIGNMENT) real pbc_simd[9 * GMX_SIMD_REAL_WIDTH];
diff --git a/src/gromacs/mdlib/settle.cpp b/src/gromacs/mdlib/settle.cpp
index df62c5c..9660960 100644
--- a/src/gromacs/mdlib/settle.cpp
+++ b/src/gromacs/mdlib/settle.cpp
@@ -823,7 +823,7 @@ void csettle(settledata*  settled,
              tensor       vir_r_m_dr,
              bool*        bErrorHasOccurred)
 {
-#if GMX_SIMD_HAVE_REAL
+#if GMX_SIMD_HAVE_REAL_ARRAY
     if (settled->bUseSimd)
     {
         /* Convert the pbc struct for SIMD */
diff --git a/src/gromacs/pbcutil/pbc_simd.h b/src/gromacs/pbcutil/pbc_simd.h
index 09ba1e7..8ccf436 100644
--- a/src/gromacs/pbcutil/pbc_simd.h
+++ b/src/gromacs/pbcutil/pbc_simd.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2015,2016,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2015,2016,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -100,6 +100,9 @@ static inline void gmx_simdcall pbc_correct_dx_simd(gmx::SimdReal* dx,
     shx = round(*dx * load<SimdReal>(pbc_simd + 7 * GMX_SIMD_REAL_WIDTH)); // load inv_bxx
     *dx = *dx - shx * load<SimdReal>(pbc_simd + 8 * GMX_SIMD_REAL_WIDTH);  // load bxx
 }
+#endif /* GMX_SIMD_HAVE_REAL */
+
+#if GMX_SIMD_HAVE_REAL_ARRAY
 
 /*! \brief Calculates the PBC corrected distance between SIMD coordinates.
  *
@@ -124,6 +127,6 @@ static inline void gmx_simdcall pbc_dx_aiuc(const real*          pbc_simd,
     pbc_correct_dx_simd(&dx[XX], &dx[YY], &dx[ZZ], pbc_simd);
 }
 
-#endif /* GMX_SIMD_HAVE_REAL */
+#endif /* GMX_SIMD_HAVE_REAL_ARRAY */
 
 #endif
diff --git a/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h b/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
index a00c9e3..78c51ee 100644
--- a/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
+++ b/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -38,7 +38,9 @@
 
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 0
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h b/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
index 3b05891..6914b62 100644
--- a/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
+++ b/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -40,7 +40,9 @@
 
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h b/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
index d91fc6d..7e1313a 100644
--- a/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
+++ b/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -51,7 +51,9 @@
 
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 0
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
 #define GMX_SIMD_HAVE_LOADU 0
 #define GMX_SIMD_HAVE_STOREU 0
 
diff --git a/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h b/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
index 76bd1cb..2df8499 100644
--- a/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
+++ b/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -57,7 +57,9 @@
 
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 // GMX_SIMD_HAVE_DOUBLE is conditionally defined further down
+// GMX_SIMD_HAVE_DOUBLE_ARRAY is conditionally defined further down
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -93,12 +95,14 @@
 #if defined(__ibmxl__) || defined(__xlC__) \
         || !(defined(__GNUC__) && ((__GNUC__ < 4) || ((__GNUC__ == 4) && (__GNUC_MINOR__ < 9))))
 #    define GMX_SIMD_HAVE_DOUBLE 1
+#    define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #    define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 #    define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #    define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
 #    define GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_DOUBLE 1
 #else
 #    define GMX_SIMD_HAVE_DOUBLE 0
+#    define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
 #    define GMX_SIMD_HAVE_DINT32_EXTRACT 0
 #    define GMX_SIMD_HAVE_DINT32_LOGICAL 0
 #    define GMX_SIMD_HAVE_DINT32_ARITHMETICS 0
diff --git a/src/gromacs/simd/impl_none/impl_none.h b/src/gromacs/simd/impl_none/impl_none.h
index f3ad5c7..26cb37e 100644
--- a/src/gromacs/simd/impl_none/impl_none.h
+++ b/src/gromacs/simd/impl_none/impl_none.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -39,7 +39,9 @@
 /* No SIMD implementation - assign 0 to all defines */
 #define GMX_SIMD 0
 #define GMX_SIMD_HAVE_FLOAT 0
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 0
 #define GMX_SIMD_HAVE_DOUBLE 0
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
 #define GMX_SIMD_HAVE_LOADU 0
 #define GMX_SIMD_HAVE_STOREU 0
 #define GMX_SIMD_HAVE_LOGICAL 0
diff --git a/src/gromacs/simd/impl_reference/impl_reference_definitions.h b/src/gromacs/simd/impl_reference/impl_reference_definitions.h
index 29dd4ae..cede940 100644
--- a/src/gromacs/simd/impl_reference/impl_reference_definitions.h
+++ b/src/gromacs/simd/impl_reference/impl_reference_definitions.h
@@ -70,9 +70,15 @@ namespace gmx
  */
 #define GMX_SIMD_HAVE_FLOAT 1
 
+//! \brief 1 when SIMD float array is supported, otherwise 0
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+
 //! \brief 1 if SIMD double support is present, otherwise 0
 #define GMX_SIMD_HAVE_DOUBLE 1
 
+//! \brief 1 when SIMD double array is supported, otherwise 0
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+
 //! \brief 1 if the SIMD implementation supports unaligned loads, otherwise 0
 #define GMX_SIMD_HAVE_LOADU 1
 
diff --git a/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h b/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
index 85c07b4..cc0f572 100644
--- a/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -39,7 +39,9 @@
 // Capability definitions for (mostly) 128-bit AVX2
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h b/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
index 8af57a2..90bf127 100644
--- a/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -39,7 +39,9 @@
 // Capability definitions for 256-bit AVX2
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h b/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
index 0978441..40c030d 100644
--- a/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
@@ -39,7 +39,9 @@
 // Capability definitions for AVX-128-FMA
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h b/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
index 13974ae..d28c1ac 100644
--- a/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -39,7 +39,9 @@
 // Capability definitions for 256-bit AVX
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h b/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
index 3a173dc..ee23b3f 100644
--- a/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
@@ -51,7 +51,9 @@
 
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h b/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
index 8d26f73..0b3f1fc 100644
--- a/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
@@ -40,7 +40,9 @@
 
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h b/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
index 2e9a6b6..97b3120 100644
--- a/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
+++ b/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -38,7 +38,9 @@
 
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h b/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
index d22389c..6bcdfb3 100644
--- a/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
+++ b/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -39,7 +39,9 @@
 // Capability definitions for SSE2.
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h b/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
index 933754c..c3e4722 100644
--- a/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
+++ b/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2018,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2018,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -39,7 +39,9 @@
 // Capability definitions for SSE4.1
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
+#define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD_HAVE_DOUBLE 1
+#define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
diff --git a/src/gromacs/simd/simd.h b/src/gromacs/simd/simd.h
index 6598e32..83a2da2 100644
--- a/src/gromacs/simd/simd.h
+++ b/src/gromacs/simd/simd.h
@@ -176,6 +176,7 @@ struct SimdDInt32Tag
 
 #if GMX_DOUBLE
 #    define GMX_SIMD_HAVE_REAL GMX_SIMD_HAVE_DOUBLE
+#    define GMX_SIMD_HAVE_REAL_ARRAY GMX_SIMD_HAVE_DOUBLE_ARRAY
 #    define GMX_SIMD_REAL_WIDTH GMX_SIMD_DOUBLE_WIDTH
 #    define GMX_SIMD_HAVE_INT32_EXTRACT GMX_SIMD_HAVE_DINT32_EXTRACT
 #    define GMX_SIMD_HAVE_INT32_LOGICAL GMX_SIMD_HAVE_DINT32_LOGICAL
@@ -192,6 +193,12 @@ struct SimdDInt32Tag
  */
 #    define GMX_SIMD_HAVE_REAL GMX_SIMD_HAVE_FLOAT
 
+/*! \brief 1 if SimdReal[] is available, otherwise 0.
+ *
+ *  \ref GMX_SIMD_HAVE_DOUBLE_ARRAY if GMX_DOUBLE is 1, otherwise \ref GMX_SIMD_HAVE_FLOAT_ARRAY.
+ */
+#    define GMX_SIMD_HAVE_REAL_ARRAY GMX_SIMD_HAVE_FLOAT_ARRAY
+
 /*! \brief Width of SimdReal.
  *
  *  \ref GMX_SIMD_DOUBLE_WIDTH if GMX_DOUBLE is 1, otherwise \ref GMX_SIMD_FLOAT_WIDTH.
-- 
1.8.3.1

From a8081f5b78c054f18b48a8d4fe3d23ad665ec324 Mon Sep 17 00:00:00 2001
From: Gilles Gouaillardet <gilles@rist.or.jp>
Date: Tue, 30 Jun 2020 19:38:31 +0900
Subject: [PATCH 07/32] Add GMX_SIMD4_HAVE_REAL_ARRAY macro

With upcoming scalable vectors, it might not always be possible to
simply declare an array of registers (e.g. Simd4Real foo[]).
This can be avoided by setting the GMX_SIMD4_HAVE_FLOAT_ARRAY and/or
GMX_SIMD4_HAVE_DOUBLE_ARRAY macros to zero.

(cherry picked from commit 27e8e5d720a768637b76cf065d95faa0c574e2e3)
---
 src/gromacs/ewald/pme_simd.h                                   | 10 +++++-----
 src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h     |  2 ++
 .../simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h |  2 ++
 src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h       |  2 ++
 src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h       |  2 ++
 src/gromacs/simd/impl_none/impl_none.h                         |  3 +++
 src/gromacs/simd/impl_reference/impl_reference_definitions.h   |  6 ++++++
 .../simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h     |  2 ++
 .../simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h     |  2 ++
 .../impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h    |  2 ++
 .../simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h       |  2 ++
 .../simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h       |  2 ++
 .../impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h    |  2 ++
 src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h       |  2 ++
 src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h     |  2 ++
 src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h |  2 ++
 src/gromacs/simd/simd.h                                        |  7 +++++++
 17 files changed, 47 insertions(+), 5 deletions(-)

diff --git a/src/gromacs/ewald/pme_simd.h b/src/gromacs/ewald/pme_simd.h
index 03c03df..8645911 100644
--- a/src/gromacs/ewald/pme_simd.h
+++ b/src/gromacs/ewald/pme_simd.h
@@ -1,7 +1,7 @@
 /*
  * This file is part of the GROMACS molecular simulation package.
  *
- * Copyright (c) 2014,2015,2017,2019, by the GROMACS development team, led by
+ * Copyright (c) 2014,2015,2017,2019,2020, by the GROMACS development team, led by
  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,
  * and including many others, as listed in the AUTHORS file in the
  * top-level source directory and at http://www.gromacs.org.
@@ -39,18 +39,18 @@
 #include "gromacs/simd/simd.h"
 
 /* Check if we have 4-wide SIMD macro support */
-#if GMX_SIMD4_HAVE_REAL
+#if GMX_SIMD4_HAVE_REAL_ARRAY
 /* Do PME spread and gather with 4-wide SIMD.
  * NOTE: SIMD is only used with PME order 4 and 5 (which are the most common).
  */
 #    define PME_SIMD4_SPREAD_GATHER
+#endif
 
-#    if GMX_SIMD_HAVE_LOADU && GMX_SIMD_HAVE_STOREU
+#if GMX_SIMD4_HAVE_REAL && GMX_SIMD_HAVE_LOADU && GMX_SIMD_HAVE_STOREU
 /* With PME-order=4 on x86, unaligned load+store is slightly faster
  * than doubling all SIMD operations when using aligned load+store.
  */
-#        define PME_SIMD4_UNALIGNED
-#    endif
+#    define PME_SIMD4_UNALIGNED
 #endif
 
 #ifdef PME_SIMD4_SPREAD_GATHER
diff --git a/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h b/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
index 78c51ee..fbd2ddd 100644
--- a/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
+++ b/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
@@ -70,7 +70,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h b/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
index 6914b62..d60ec88 100644
--- a/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
+++ b/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
@@ -71,7 +71,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h b/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
index 7e1313a..7013efe 100644
--- a/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
+++ b/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
@@ -83,7 +83,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h b/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
index 2df8499..28701ba 100644
--- a/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
+++ b/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
@@ -87,7 +87,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_FLOAT 0  // No need for half-simd, width is 4
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0 // No need for half-simd, width is 2
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
 
 // With GCC, only version 4.9 or later supports all parts of double precision VSX.
 // We check explicitly for xlc, since that compiler appears to like pretending it is gcc,
diff --git a/src/gromacs/simd/impl_none/impl_none.h b/src/gromacs/simd/impl_none/impl_none.h
index 26cb37e..3b4bc3d 100644
--- a/src/gromacs/simd/impl_none/impl_none.h
+++ b/src/gromacs/simd/impl_none/impl_none.h
@@ -53,7 +53,10 @@
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 0
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 0
 #define GMX_SIMD4_HAVE_FLOAT 0
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 0
 #define GMX_SIMD4_HAVE_DOUBLE 0
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+
 #define GMX_SIMD_HAVE_HSIMD_UTIL_FLOAT 0
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0
 
diff --git a/src/gromacs/simd/impl_reference/impl_reference_definitions.h b/src/gromacs/simd/impl_reference/impl_reference_definitions.h
index cede940..cea8d8c 100644
--- a/src/gromacs/simd/impl_reference/impl_reference_definitions.h
+++ b/src/gromacs/simd/impl_reference/impl_reference_definitions.h
@@ -226,9 +226,15 @@ namespace gmx
 //! \brief 1 if implementation provides \ref gmx::Simd4Float, otherwise 0.
 #define GMX_SIMD4_HAVE_FLOAT 1
 
+//! \brief 1 when SIMD4 float array is supported, otherwise 0
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+
 //! \brief 1 if the implementation provides \ref gmx::Simd4Double, otherwise 0.
 #define GMX_SIMD4_HAVE_DOUBLE 1
 
+//! \brief 1 when SIMD4 double array is supported, otherwise 0
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+
 //! \brief Width of the \ref gmx::SimdFInt32 datatype.
 #define GMX_SIMD_FINT32_WIDTH GMX_SIMD_FLOAT_WIDTH
 
diff --git a/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h b/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
index cc0f572..e191974 100644
--- a/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
@@ -70,7 +70,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0 // No need for half-simd, width is 2
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h b/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
index 90bf127..0ab7aa3 100644
--- a/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
@@ -71,7 +71,9 @@
 #define GMX_SIMD_HAVE_4NSIMD_UTIL_FLOAT 1
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 8
diff --git a/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h b/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
index 40c030d..3be35ce 100644
--- a/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
@@ -71,7 +71,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0 // No need for half-simd, width is 2
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 1 // Uses 256-bit avx for SIMD4-double
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h b/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
index d28c1ac..262cb78 100644
--- a/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
@@ -71,7 +71,9 @@
 #define GMX_SIMD_HAVE_4NSIMD_UTIL_FLOAT 1
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 8
diff --git a/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h b/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
index ee23b3f..5a2e1c5 100644
--- a/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
@@ -87,7 +87,9 @@
 #define GMX_SIMD_HAVE_4NSIMD_UTIL_DOUBLE 1
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 16
diff --git a/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h b/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
index 0b3f1fc..d148746 100644
--- a/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
@@ -76,7 +76,9 @@
 #define GMX_SIMD_HAVE_4NSIMD_UTIL_DOUBLE 1
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 16
diff --git a/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h b/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
index 97b3120..a5ebc42 100644
--- a/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
+++ b/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
@@ -69,7 +69,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 1
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 16
diff --git a/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h b/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
index 6bcdfb3..8f8ff1e 100644
--- a/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
+++ b/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
@@ -70,7 +70,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0 // No need for half-simd, width is 2
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h b/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
index c3e4722..9f9ce11 100644
--- a/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
+++ b/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
@@ -70,7 +70,9 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0 // No need for half-simd, width is 2
 
 #define GMX_SIMD4_HAVE_FLOAT 1
+#define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
+#define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/simd.h b/src/gromacs/simd/simd.h
index 83a2da2..de53f1a 100644
--- a/src/gromacs/simd/simd.h
+++ b/src/gromacs/simd/simd.h
@@ -185,6 +185,7 @@ struct SimdDInt32Tag
         GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_DOUBLE
 #    define GMX_SIMD_HAVE_HSIMD_UTIL_REAL GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE
 #    define GMX_SIMD4_HAVE_REAL GMX_SIMD4_HAVE_DOUBLE
+#    define GMX_SIMD4_HAVE_REAL_ARRAY GMX_SIMD4_HAVE_DOUBLE_ARRAY
 #else // GMX_DOUBLE
 
 /*! \brief 1 if SimdReal is available, otherwise 0.
@@ -247,6 +248,12 @@ struct SimdDInt32Tag
  */
 #    define GMX_SIMD4_HAVE_REAL GMX_SIMD4_HAVE_FLOAT
 
+/*! \brief 1 if Simd4Real[] is available, otherwise 0.
+ *
+ *  \ref GMX_SIMD4_HAVE_DOUBLE_ARRAY if GMX_DOUBLE is 1, otherwise \ref GMX_SIMD4_HAVE_FLOAT_ARRAY.
+ */
+#    define GMX_SIMD4_HAVE_REAL_ARRAY GMX_SIMD4_HAVE_FLOAT_ARRAY
+
 #endif // GMX_DOUBLE
 
 //! \}  end of name-group describing high-level capabilities
-- 
1.8.3.1

From c75d844123b45176ddd4f570da2a181fe710ffef Mon Sep 17 00:00:00 2001
From: Gilles Gouaillardet <gilles@rist.or.jp>
Date: Sat, 29 Feb 2020 16:39:05 +0900
Subject: [PATCH 08/32] tests: use macros instead of global variables for
 scalable vectors.

If SimdReal, Simd4Real and/or SimdFint32 are scalable vectors, their size
is unknown at compile time and these types cannot be used to declare
global variables. In that case only, define them as macros instead
of global variables.

(cherry picked from commit a9e8272909ebb48614278a9542aee1ff6fed6466)
---
 .../simd/impl_arm_neon/impl_arm_neon_definitions.h |   6 ++
 .../impl_arm_neon_asimd_definitions.h              |   6 ++
 .../simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h   |   6 ++
 .../simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h   |   8 ++
 src/gromacs/simd/impl_none/impl_none.h             |   4 +
 .../impl_reference/impl_reference_definitions.h    |  18 ++++
 .../impl_x86_avx2_128_definitions.h                |   6 ++
 .../impl_x86_avx2_256_definitions.h                |   6 ++
 .../impl_x86_avx_128_fma_definitions.h             |   6 ++
 .../impl_x86_avx_256_definitions.h                 |   8 +-
 .../impl_x86_avx_512_definitions.h                 |   6 ++
 .../impl_x86_avx_512_knl_definitions.h             |   6 ++
 .../simd/impl_x86_mic/impl_x86_mic_definitions.h   |   6 ++
 .../simd/impl_x86_sse2/impl_x86_sse2_definitions.h |   6 ++
 .../impl_x86_sse4_1/impl_x86_sse4_1_definitions.h  |   6 ++
 src/gromacs/simd/simd.h                            |  22 +++++
 src/gromacs/simd/tests/simd.cpp                    |   6 +-
 src/gromacs/simd/tests/simd.h                      | 101 +++++++++++++++++++--
 src/gromacs/simd/tests/simd4.cpp                   |  12 ++-
 src/gromacs/simd/tests/simd4.h                     |  54 ++++++++++-
 20 files changed, 282 insertions(+), 17 deletions(-)

diff --git a/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h b/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
index fbd2ddd..a4c613c 100644
--- a/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
+++ b/src/gromacs/simd/impl_arm_neon/impl_arm_neon_definitions.h
@@ -39,8 +39,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 0
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 0
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -48,9 +50,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 0
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 0
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 0
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 0
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT \
     0 // Although there is support, it is disabled in GROMACS, because rsqrtIter does not work correctly for inputs near MAX_FLOAT
@@ -71,8 +75,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h b/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
index d60ec88..d7c2651 100644
--- a/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
+++ b/src/gromacs/simd/impl_arm_neon_asimd/impl_arm_neon_asimd_definitions.h
@@ -41,8 +41,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -50,9 +52,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 1
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 1
@@ -72,8 +76,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h b/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
index 7013efe..74f82d2 100644
--- a/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
+++ b/src/gromacs/simd/impl_ibm_vmx/impl_ibm_vmx_definitions.h
@@ -52,8 +52,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 0
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 0
 #define GMX_SIMD_HAVE_LOADU 0
 #define GMX_SIMD_HAVE_STOREU 0
 
@@ -62,9 +64,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 0
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 0
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 0
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 0
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 0
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -84,8 +88,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h b/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
index 28701ba..dcc89ae 100644
--- a/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
+++ b/src/gromacs/simd/impl_ibm_vsx/impl_ibm_vsx_definitions.h
@@ -58,6 +58,7 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 // GMX_SIMD_HAVE_DOUBLE is conditionally defined further down
 // GMX_SIMD_HAVE_DOUBLE_ARRAY is conditionally defined further down
 #define GMX_SIMD_HAVE_LOADU 1
@@ -67,6 +68,7 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 // GMX_SIMD_HAVE_DINT32_EXTRACT is conditionally defined further down
 // GMX_SIMD_HAVE_DINT32_LOGICAL is conditionally defined further down
 // GMX_SIMD_HAVE_DINT32_ARITHMETICS is conditionally defined further down
@@ -88,8 +90,10 @@
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0 // No need for half-simd, width is 2
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 0
 
 // With GCC, only version 4.9 or later supports all parts of double precision VSX.
 // We check explicitly for xlc, since that compiler appears to like pretending it is gcc,
@@ -98,16 +102,20 @@
         || !(defined(__GNUC__) && ((__GNUC__ < 4) || ((__GNUC__ == 4) && (__GNUC_MINOR__ < 9))))
 #    define GMX_SIMD_HAVE_DOUBLE 1
 #    define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#    define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #    define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 #    define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #    define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#    define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #    define GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_DOUBLE 1
 #else
 #    define GMX_SIMD_HAVE_DOUBLE 0
 #    define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
+#    define GMX_SIMD_HAVE_DOUBLE_GLOBAL 0
 #    define GMX_SIMD_HAVE_DINT32_EXTRACT 0
 #    define GMX_SIMD_HAVE_DINT32_LOGICAL 0
 #    define GMX_SIMD_HAVE_DINT32_ARITHMETICS 0
+#    define GMX_SIMD_HAVE_DINT32_GLOBAL 0
 #    define GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_DOUBLE 0
 #endif
 
diff --git a/src/gromacs/simd/impl_none/impl_none.h b/src/gromacs/simd/impl_none/impl_none.h
index 3b4bc3d..4f43815 100644
--- a/src/gromacs/simd/impl_none/impl_none.h
+++ b/src/gromacs/simd/impl_none/impl_none.h
@@ -40,8 +40,10 @@
 #define GMX_SIMD 0
 #define GMX_SIMD_HAVE_FLOAT 0
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 0
+#define GMX_SIMD_HAVE_GLOBAL_FLOAT 0
 #define GMX_SIMD_HAVE_DOUBLE 0
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD_HAVE_GLOBAL_DOUBLE 0
 #define GMX_SIMD_HAVE_LOADU 0
 #define GMX_SIMD_HAVE_STOREU 0
 #define GMX_SIMD_HAVE_LOGICAL 0
@@ -54,8 +56,10 @@
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 0
 #define GMX_SIMD4_HAVE_FLOAT 0
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 0
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 0
 #define GMX_SIMD4_HAVE_DOUBLE 0
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 0
 
 #define GMX_SIMD_HAVE_HSIMD_UTIL_FLOAT 0
 #define GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE 0
diff --git a/src/gromacs/simd/impl_reference/impl_reference_definitions.h b/src/gromacs/simd/impl_reference/impl_reference_definitions.h
index cea8d8c..dc8869f 100644
--- a/src/gromacs/simd/impl_reference/impl_reference_definitions.h
+++ b/src/gromacs/simd/impl_reference/impl_reference_definitions.h
@@ -73,12 +73,18 @@ namespace gmx
 //! \brief 1 when SIMD float array is supported, otherwise 0
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
 
+//! \brief 1 when SimdFloat can be a global variable, otherwise 0
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
+
 //! \brief 1 if SIMD double support is present, otherwise 0
 #define GMX_SIMD_HAVE_DOUBLE 1
 
 //! \brief 1 when SIMD double array is supported, otherwise 0
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
 
+//! \brief 1 when SimdDouble can be a global variable, otherwise 0
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
+
 //! \brief 1 if the SIMD implementation supports unaligned loads, otherwise 0
 #define GMX_SIMD_HAVE_LOADU 1
 
@@ -106,6 +112,9 @@ namespace gmx
 //! \brief 1 if SIMD arithmetic ops are supported for \ref gmx::SimdFInt32, otherwise 0
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
 
+//! \brief 1 if SimdFInt32 can be a global variable, otherwse 0
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
+
 //! \brief Support for extracting integer from \ref gmx::SimdDInt32 (1/0 for present/absent)
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 
@@ -115,6 +124,9 @@ namespace gmx
 //! \brief 1 if SIMD arithmetic ops are supported for \ref gmx::SimdDInt32, otherwise 0
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
 
+//! \brief 1 if SimdDInt32 can be a global variable, otherwise 0
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
+
 /*! \brief 1 if implementation provides single precision copysign()
  *
  *  Only used in simd_math.h to selectively override the generic implementation.
@@ -229,12 +241,18 @@ namespace gmx
 //! \brief 1 when SIMD4 float array is supported, otherwise 0
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
 
+//! \brief 1 when Simd4Float can be a global variable, otherwise 0
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
+
 //! \brief 1 if the implementation provides \ref gmx::Simd4Double, otherwise 0.
 #define GMX_SIMD4_HAVE_DOUBLE 1
 
 //! \brief 1 when SIMD4 double array is supported, otherwise 0
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
 
+//! \brief 1 when Simd4Double can be a global variable, otherwise 0
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
+
 //! \brief Width of the \ref gmx::SimdFInt32 datatype.
 #define GMX_SIMD_FINT32_WIDTH GMX_SIMD_FLOAT_WIDTH
 
diff --git a/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h b/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
index e191974..68f57bc 100644
--- a/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx2_128/impl_x86_avx2_128_definitions.h
@@ -40,8 +40,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -49,9 +51,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -71,8 +75,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h b/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
index 0ab7aa3..0d4bfcb 100644
--- a/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx2_256/impl_x86_avx2_256_definitions.h
@@ -40,8 +40,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -49,9 +51,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -72,8 +76,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 8
diff --git a/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h b/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
index 3be35ce..5a849f7 100644
--- a/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_128_fma/impl_x86_avx_128_fma_definitions.h
@@ -40,8 +40,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -49,9 +51,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -72,8 +76,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 1 // Uses 256-bit avx for SIMD4-double
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h b/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
index 262cb78..4745d7d 100644
--- a/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_256/impl_x86_avx_256_definitions.h
@@ -40,8 +40,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -49,9 +51,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1     // Emulated
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 0     // AVX1 cannot do 256-bit int shifts
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 0 // AVX1 cannot do 256-bit int +,-,*
-#define GMX_SIMD_HAVE_DINT32_EXTRACT 1     // Native, since we use __m128i
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
+#define GMX_SIMD_HAVE_DINT32_EXTRACT 1 // Native, since we use __m128i
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -72,8 +76,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 8
diff --git a/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h b/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
index 5a2e1c5..a7db311 100644
--- a/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_512/impl_x86_avx_512_definitions.h
@@ -52,8 +52,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -61,12 +63,14 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 0
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 // Technically it is straightforward to emulate extract on AVX-512 through
 // memory operations, but when applied to 16 elements as part of a table lookup
 // it will be faster to just store the entire vector once, so we avoid setting it.
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 0
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 1
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -88,8 +92,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 16
diff --git a/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h b/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
index d148746..ebc5a1a 100644
--- a/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
+++ b/src/gromacs/simd/impl_x86_avx_512_knl/impl_x86_avx_512_knl_definitions.h
@@ -41,8 +41,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -50,12 +52,14 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 0
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 // Technically it is straightforward to emulate extract on AVX-512F through
 // memory operations, but when applied to 16 elements as part of a table lookup
 // it will be faster to just store the entire vector once, so we avoid setting it.
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 0
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 1
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -77,8 +81,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 16
diff --git a/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h b/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
index a5ebc42..f0cf975 100644
--- a/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
+++ b/src/gromacs/simd/impl_x86_mic/impl_x86_mic_definitions.h
@@ -39,8 +39,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -48,9 +50,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -70,8 +74,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 1
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 1
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 16
diff --git a/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h b/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
index 8f8ff1e..53c9315 100644
--- a/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
+++ b/src/gromacs/simd/impl_x86_sse2/impl_x86_sse2_definitions.h
@@ -40,8 +40,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -49,9 +51,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1 // No SSE2 instruction, but use shifts
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 1 // No SSE2 instruction, but use shifts
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -71,8 +75,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h b/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
index 9f9ce11..ca8a4c8 100644
--- a/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
+++ b/src/gromacs/simd/impl_x86_sse4_1/impl_x86_sse4_1_definitions.h
@@ -40,8 +40,10 @@
 #define GMX_SIMD 1
 #define GMX_SIMD_HAVE_FLOAT 1
 #define GMX_SIMD_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD_HAVE_DOUBLE 1
 #define GMX_SIMD_HAVE_DOUBLE_ARRAY 1
+#define GMX_SIMD_HAVE_DOUBLE_GLOBAL 1
 #define GMX_SIMD_HAVE_LOADU 1
 #define GMX_SIMD_HAVE_STOREU 1
 #define GMX_SIMD_HAVE_LOGICAL 1
@@ -49,9 +51,11 @@
 #define GMX_SIMD_HAVE_FINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_FINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_FINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_FINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_DINT32_EXTRACT 1
 #define GMX_SIMD_HAVE_DINT32_LOGICAL 1
 #define GMX_SIMD_HAVE_DINT32_ARITHMETICS 1
+#define GMX_SIMD_HAVE_DINT32_GLOBAL 1
 #define GMX_SIMD_HAVE_NATIVE_COPYSIGN_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RSQRT_ITER_FLOAT 0
 #define GMX_SIMD_HAVE_NATIVE_RCP_ITER_FLOAT 0
@@ -71,8 +75,10 @@
 
 #define GMX_SIMD4_HAVE_FLOAT 1
 #define GMX_SIMD4_HAVE_FLOAT_ARRAY 1
+#define GMX_SIMD4_HAVE_FLOAT_GLOBAL 1
 #define GMX_SIMD4_HAVE_DOUBLE 0
 #define GMX_SIMD4_HAVE_DOUBLE_ARRAY 0
+#define GMX_SIMD4_HAVE_DOUBLE_GLOBAL 0
 
 // Implementation details
 #define GMX_SIMD_FLOAT_WIDTH 4
diff --git a/src/gromacs/simd/simd.h b/src/gromacs/simd/simd.h
index de53f1a..22d2c13 100644
--- a/src/gromacs/simd/simd.h
+++ b/src/gromacs/simd/simd.h
@@ -177,15 +177,18 @@ struct SimdDInt32Tag
 #if GMX_DOUBLE
 #    define GMX_SIMD_HAVE_REAL GMX_SIMD_HAVE_DOUBLE
 #    define GMX_SIMD_HAVE_REAL_ARRAY GMX_SIMD_HAVE_DOUBLE_ARRAY
+#    define GMX_SIMD_HAVE_REAL_GLOBAL GMX_SIMD_HAVE_DOUBLE_GLOBAL
 #    define GMX_SIMD_REAL_WIDTH GMX_SIMD_DOUBLE_WIDTH
 #    define GMX_SIMD_HAVE_INT32_EXTRACT GMX_SIMD_HAVE_DINT32_EXTRACT
 #    define GMX_SIMD_HAVE_INT32_LOGICAL GMX_SIMD_HAVE_DINT32_LOGICAL
 #    define GMX_SIMD_HAVE_INT32_ARITHMETICS GMX_SIMD_HAVE_DINT32_ARITHMETICS
+#    define GMX_SIMD_HAVE_INT32_GLOBAL GMX_SIMD_HAVE_DINT32_GLOBAL
 #    define GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_REAL \
         GMX_SIMD_HAVE_GATHER_LOADU_BYSIMDINT_TRANSPOSE_DOUBLE
 #    define GMX_SIMD_HAVE_HSIMD_UTIL_REAL GMX_SIMD_HAVE_HSIMD_UTIL_DOUBLE
 #    define GMX_SIMD4_HAVE_REAL GMX_SIMD4_HAVE_DOUBLE
 #    define GMX_SIMD4_HAVE_REAL_ARRAY GMX_SIMD4_HAVE_DOUBLE_ARRAY
+#    define GMX_SIMD4_HAVE_REAL_GLOBAL GMX_SIMD4_HAVE_DOUBLE_GLOBAL
 #else // GMX_DOUBLE
 
 /*! \brief 1 if SimdReal is available, otherwise 0.
@@ -200,6 +203,12 @@ struct SimdDInt32Tag
  */
 #    define GMX_SIMD_HAVE_REAL_ARRAY GMX_SIMD_HAVE_FLOAT_ARRAY
 
+/*! \brief 1 if SimdReal can be a global variable, otherwise 0.
+ *
+ *  \ref GMX_SIMD_HAVE_DOUBLE_GLOBAL if GMX_DOUBLE is 1, otherwise \ref GMX_SIMD_HAVE_FLOAT_GLOBAL.
+ */
+#    define GMX_SIMD_HAVE_REAL_GLOBAL GMX_SIMD_HAVE_FLOAT_GLOBAL
+
 /*! \brief Width of SimdReal.
  *
  *  \ref GMX_SIMD_DOUBLE_WIDTH if GMX_DOUBLE is 1, otherwise \ref GMX_SIMD_FLOAT_WIDTH.
@@ -220,6 +229,13 @@ struct SimdDInt32Tag
  */
 #    define GMX_SIMD_HAVE_INT32_LOGICAL GMX_SIMD_HAVE_FINT32_LOGICAL
 
+/*! \brief 1 if SimdInt32 can be a global variable, otherwise 0.
+ *
+ *  \ref GMX_SIMD_HAVE_DINT32_GLOBAL if GMX_DOUBLE is 1, otherwise
+ *  \ref GMX_SIMD_HAVE_FINT32_GLOBAL.
+ */
+#    define GMX_SIMD_HAVE_INT32_GLOBAL GMX_SIMD_HAVE_FINT32_GLOBAL
+
 /*! \brief 1 if arithmetic ops are supported on SimdInt32, otherwise 0.
  *
  *  \ref GMX_SIMD_HAVE_DINT32_ARITHMETICS if GMX_DOUBLE is 1, otherwise
@@ -254,6 +270,12 @@ struct SimdDInt32Tag
  */
 #    define GMX_SIMD4_HAVE_REAL_ARRAY GMX_SIMD4_HAVE_FLOAT_ARRAY
 
+/*! \brief 1 if Simd4Real can be a global variable, otherwise 0.
+ *
+ *  \ref GMX_SIMD4_HAVE_DOUBLE_GLOBAL if GMX_DOUBLE is 1, otherwise \ref GMX_SIMD4_HAVE_FLOAT_GLOBAL.
+ */
+#    define GMX_SIMD4_HAVE_REAL_GLOBAL GMX_SIMD4_HAVE_FLOAT_GLOBAL
+
 #endif // GMX_DOUBLE
 
 //! \}  end of name-group describing high-level capabilities
diff --git a/src/gromacs/simd/tests/simd.cpp b/src/gromacs/simd/tests/simd.cpp
index e519643..d6ee184 100644
--- a/src/gromacs/simd/tests/simd.cpp
+++ b/src/gromacs/simd/tests/simd.cpp
@@ -63,7 +63,7 @@ namespace test
  * occasionally have many digits that need to be exactly right, and keeping
  * them in a single place makes sure they are consistent.
  */
-#    if GMX_SIMD_HAVE_REAL
+#    if GMX_SIMD_HAVE_REAL && GMX_SIMD_HAVE_REAL_GLOBAL
 const SimdReal rSimd_c0c1c2 = setSimdRealFrom3R(c0, c1, c2);
 const SimdReal rSimd_c3c4c5 = setSimdRealFrom3R(c3, c4, c5);
 const SimdReal rSimd_c6c7c8 = setSimdRealFrom3R(c6, c7, c8);
@@ -110,7 +110,7 @@ const SimdReal rSimd_logicalResultOr = setSimdRealFrom1R(1.8666534423828125); //
 #        endif                                    // GMX_SIMD_HAVE_LOGICAL
 
 #    endif // GMX_SIMD_HAVE_REAL
-#    if GMX_SIMD_HAVE_INT32_ARITHMETICS
+#    if GMX_SIMD_HAVE_INT32_ARITHMETICS && GMX_SIMD_HAVE_INT32_GLOBAL
 const SimdInt32 iSimd_1_2_3    = setSimdIntFrom3I(1, 2, 3);
 const SimdInt32 iSimd_4_5_6    = setSimdIntFrom3I(4, 5, 6);
 const SimdInt32 iSimd_7_8_9    = setSimdIntFrom3I(7, 8, 9);
@@ -119,7 +119,7 @@ const SimdInt32 iSimd_1M_2M_3M = setSimdIntFrom3I(1000000, 2000000, 3000000);
 const SimdInt32 iSimd_4M_5M_6M = setSimdIntFrom3I(4000000, 5000000, 6000000);
 const SimdInt32 iSimd_5M_7M_9M = setSimdIntFrom3I(5000000, 7000000, 9000000);
 #    endif
-#    if GMX_SIMD_HAVE_INT32_LOGICAL
+#    if GMX_SIMD_HAVE_INT32_LOGICAL && GMX_SIMD_HAVE_INT32_GLOBAL
 const SimdInt32 iSimd_0xF0F0F0F0 = setSimdIntFrom1I(0xF0F0F0F0);
 const SimdInt32 iSimd_0xCCCCCCCC = setSimdIntFrom1I(0xCCCCCCCC);
 #    endif
diff --git a/src/gromacs/simd/tests/simd.h b/src/gromacs/simd/tests/simd.h
index 9e94c2e..ffc6f6c 100644
--- a/src/gromacs/simd/tests/simd.h
+++ b/src/gromacs/simd/tests/simd.h
@@ -109,6 +109,7 @@ namespace test
  * them in a single place makes sure they are consistent.
  */
 #    if GMX_SIMD_HAVE_REAL
+#        if GMX_SIMD_HAVE_REAL_GLOBAL
 extern const SimdReal rSimd_c0c1c2; //!< c0,c1,c2 repeated
 extern const SimdReal rSimd_c3c4c5; //!< c3,c4,c5 repeated
 extern const SimdReal rSimd_c6c7c8; //!< c6,c7,c8 repeated
@@ -127,17 +128,17 @@ extern const SimdReal rSimd_m3p75; //!< Negative value that rounds down.
 //! Three large floating-point values whose exponents are >32.
 extern const SimdReal rSimd_Exp;
 
-#        if GMX_SIMD_HAVE_LOGICAL
+#            if GMX_SIMD_HAVE_LOGICAL
 extern const SimdReal rSimd_logicalA;         //!< Bit pattern to test logical ops
 extern const SimdReal rSimd_logicalB;         //!< Bit pattern to test logical ops
 extern const SimdReal rSimd_logicalResultOr;  //!< Result or bitwise 'or' of A and B
 extern const SimdReal rSimd_logicalResultAnd; //!< Result or bitwise 'and' of A and B
-#        endif                                // GMX_SIMD_HAVE_LOGICAL
+#            endif                            // GMX_SIMD_HAVE_LOGICAL
 
-#        if GMX_SIMD_HAVE_DOUBLE && GMX_DOUBLE
+#            if GMX_SIMD_HAVE_DOUBLE && GMX_DOUBLE
 // Make sure we also test exponents outside single precision when we use double
 extern const SimdReal rSimd_ExpDouble;
-#        endif
+#            endif
 // Magic FP numbers corresponding to specific bit patterns
 extern const SimdReal rSimd_Bits1; //!< Pattern F0 repeated to fill single/double.
 extern const SimdReal rSimd_Bits2; //!< Pattern CC repeated to fill single/double.
@@ -145,8 +146,74 @@ extern const SimdReal rSimd_Bits3; //!< Pattern C0 repeated to fill single/doubl
 extern const SimdReal rSimd_Bits4; //!< Pattern 0C repeated to fill single/double.
 extern const SimdReal rSimd_Bits5; //!< Pattern FC repeated to fill single/double.
 extern const SimdReal rSimd_Bits6; //!< Pattern 3C repeated to fill single/double.
-#    endif                         // GMX_SIMD_HAVE_REAL
+#        else                      // GMX_SIMD_HAVE_REAL_GLOBAL
+//!< c0,c1,c2 repeated
+#            define rSimd_c0c1c2 setSimdRealFrom3R(c0, c1, c2)
+//!< c3,c4,c5 repeated
+#            define rSimd_c3c4c5 setSimdRealFrom3R(c3, c4, c5)
+//!< c6,c7,c8 repeated
+#            define rSimd_c6c7c8 setSimdRealFrom3R(c6, c7, c8)
+//!< c3,c0,c4 repeated
+#            define rSimd_c3c0c4 setSimdRealFrom3R(c3, c0, c4)
+//!< c4,c6,c8 repeated
+#            define rSimd_c4c6c8 setSimdRealFrom3R(c4, c6, c8)
+//!< c7,c2,c3 repeated
+#            define rSimd_c7c2c3 setSimdRealFrom3R(c7, c2, c3)
+//!< -c0,-c1,-c2 repeated
+#            define rSimd_m0m1m2 setSimdRealFrom3R(-c0, -c1, -c2)
+//!< -c3,-c0,-c4 repeated
+#            define rSimd_m3m0m4 setSimdRealFrom3R(-c3, -c0, -c4)
+
+//!< Value that rounds down.
+#            define rSimd_2p25 setSimdRealFrom1R(2.25)
+//!< Value that rounds down.
+#            define rSimd_3p25 setSimdRealFrom1R(3.25)
+//!< Value that rounds up.
+#            define rSimd_3p75 setSimdRealFrom1R(3.75)
+//!< Negative value that rounds up.
+#            define rSimd_m2p25 setSimdRealFrom1R(-2.25)
+//!< Negative value that rounds up.
+#            define rSimd_m3p25 setSimdRealFrom1R(-3.25)
+//!< Negative value that rounds down.
+#            define rSimd_m3p75 setSimdRealFrom1R(-3.75)
+//! Three large floating-point values whose exponents are >32.
+#            define rSimd_Exp                                                                       \
+                setSimdRealFrom3R(1.4055235171027452623914516e+18, 5.3057102734253445623914516e-13, \
+                                  -2.1057102745623934534514516e+16)
+
+#            if GMX_SIMD_HAVE_DOUBLE && GMX_DOUBLE
+// Make sure we also test exponents outside single precision when we use double
+#                define rSimd_ExpDouble                                                                 \
+                    setSimdRealFrom3R(6.287393598732017379054414e+176, 8.794495252903116023030553e-140, \
+                                      -3.637060701570496477655022e+202)
+#            endif // GMX_SIMD_HAVE_DOUBLE && GMX_DOUBLE
+
+#            if GMX_SIMD_HAVE_LOGICAL
+#                if GMX_DOUBLE
+//!< Bit pattern to test logical ops
+#                    define rSimd_logicalA setSimdRealFrom1R(1.3333333332557231188)
+//!< Bit pattern to test logical ops
+#                    define rSimd_logicalB setSimdRealFrom1R(1.7999999998137354851)
+//!< Result or bitwise 'or' of A and B
+#                    define rSimd_logicalResultAnd setSimdRealFrom1R(1.266666666604578495)
+//!< Result or bitwise 'and' of A and B
+#                    define rSimd_logicalResultOr setSimdRealFrom1R(1.8666666664648801088)
+#                else // GMX_DOUBLE
+//!< Bit pattern to test logical ops
+#                    define rSimd_logicalA setSimdRealFrom1R(1.3333282470703125)
+//!< Bit pattern to test logical ops
+#                    define rSimd_logicalB setSimdRealFrom1R(1.79998779296875)
+//!< Result or bitwise 'or' of A and B
+#                    define rSimd_logicalResultAnd setSimdRealFrom1R(1.26666259765625)
+//!< Result or bitwise 'and' of A and B
+#                    define rSimd_logicalResultOr setSimdRealFrom1R(1.8666534423828125)
+#                endif // GMX_DOUBLE
+#            endif     // GMX_SIMD_HAVE_LOGICAL
+
+#        endif // GMX_SIMD_HAVE_REAL_GLOBAL
+#    endif     // GMX_SIMD_HAVE_REAL
 #    if GMX_SIMD_HAVE_INT32_ARITHMETICS
+#        if GMX_SIMD_HAVE_INT32_GLOBAL
 extern const SimdInt32 iSimd_1_2_3;    //!< Three generic ints.
 extern const SimdInt32 iSimd_4_5_6;    //!< Three generic ints.
 extern const SimdInt32 iSimd_7_8_9;    //!< Three generic ints.
@@ -154,13 +221,35 @@ extern const SimdInt32 iSimd_5_7_9;    //!< iSimd_1_2_3 + iSimd_4_5_6.
 extern const SimdInt32 iSimd_1M_2M_3M; //!< Term1 for 32bit add/sub.
 extern const SimdInt32 iSimd_4M_5M_6M; //!< Term2 for 32bit add/sub.
 extern const SimdInt32 iSimd_5M_7M_9M; //!< iSimd_1M_2M_3M + iSimd_4M_5M_6M.
+#        else                          // GMX_SIMD_HAVE_INT32_GLOBAL
+//!< Three generic ints.
+#            define iSimd_1_2_3 setSimdIntFrom3I(1, 2, 3)
+//!< Three generic ints.
+#            define iSimd_4_5_6 setSimdIntFrom3I(4, 5, 6)
+//!< Three generic ints.
+#            define iSimd_7_8_9 setSimdIntFrom3I(7, 8, 9)
+//!< iSimd_1_2_3 + iSimd_4_5_6.
+#            define iSimd_5_7_9 setSimdIntFrom3I(5, 7, 9)
+//!< Term1 for 32bit add/sub.
+#            define iSimd_1M_2M_3M setSimdIntFrom3I(1000000, 2000000, 3000000)
+//!< Term2 for 32bit add/sub.
+#            define iSimd_4M_5M_6M setSimdIntFrom3I(4000000, 5000000, 6000000)
+//!< iSimd_1M_2M_3M + iSimd_4M_5M_6M.
+#            define iSimd_5M_7M_9M setSimdIntFrom3I(5000000, 7000000, 9000000)
+#        endif // GMX_SIMD_HAVE_INT32_GLOBAL
 #    endif
 #    if GMX_SIMD_HAVE_INT32_LOGICAL
+#        if GMX_SIMD_HAVE_INT32_GLOBAL
 extern const SimdInt32 iSimd_0xF0F0F0F0; //!< Bitpattern to test integer logical operations.
 extern const SimdInt32 iSimd_0xCCCCCCCC; //!< Bitpattern to test integer logical operations.
+#        else                            // GMX_SIMD_HAVE_INT32_GLOBAL
+//!< Bitpattern to test integer logical operations.
+#            define iSimd_0xF0F0F0F0 setSimdIntFrom1I(0xF0F0F0F0)
+//!< Bitpattern to test integer logical operations.
+#            define iSimd_0xCCCCCCCC setSimdIntFrom1I(0xCCCCCCCC)
+#        endif // GMX_SIMD_HAVE_INT32_GLOBAL
 #    endif
 
-
 /*! \internal
  * \brief
  * Test fixture for SIMD tests.
diff --git a/src/gromacs/simd/tests/simd4.cpp b/src/gromacs/simd/tests/simd4.cpp
index dca3403..173bfef 100644
--- a/src/gromacs/simd/tests/simd4.cpp
+++ b/src/gromacs/simd/tests/simd4.cpp
@@ -54,6 +54,7 @@ namespace test
 
 #    if GMX_SIMD4_HAVE_REAL
 
+#        if GMX_SIMD4_HAVE_REAL_GLOBAL
 const Simd4Real rSimd4_c0c1c2 = setSimd4RealFrom3R(c0, c1, c2);
 const Simd4Real rSimd4_c3c4c5 = setSimd4RealFrom3R(c3, c4, c5);
 const Simd4Real rSimd4_c6c7c8 = setSimd4RealFrom3R(c6, c7, c8);
@@ -67,10 +68,10 @@ const Simd4Real rSimd4_3p75   = setSimd4RealFrom1R(3.75);
 const Simd4Real rSimd4_m2p25  = setSimd4RealFrom1R(-2.25);
 const Simd4Real rSimd4_m3p75  = setSimd4RealFrom1R(-3.75);
 
-#        if GMX_SIMD_HAVE_LOGICAL
+#            if GMX_SIMD_HAVE_LOGICAL
 // The numbers below all have exponent (2^0), which will not change with AND/OR operations.
 // We also leave the last part of the mantissa as zeros, to avoid rounding issues in the compiler
-#            if GMX_DOUBLE
+#                if GMX_DOUBLE
 const Simd4Real rSimd4_logicalA =
         setSimd4RealFrom1R(1.3333333332557231188); // mantissa 01010101010101010101010101010101
 const Simd4Real rSimd4_logicalB =
@@ -79,13 +80,14 @@ const Simd4Real rSimd4_logicalResultAnd =
         setSimd4RealFrom1R(1.266666666604578495); // mantissa 01000100010001000100010001000100
 const Simd4Real rSimd4_logicalResultOr =
         setSimd4RealFrom1R(1.8666666664648801088); // mantissa 11011101110111011101110111011101
-#            else                                  // GMX_DOUBLE
+#                else                              // GMX_DOUBLE
 const Simd4Real rSimd4_logicalA = setSimd4RealFrom1R(1.3333282470703125); // mantissa 0101010101010101
 const Simd4Real rSimd4_logicalB = setSimd4RealFrom1R(1.79998779296875); // mantissa 1100110011001100
 const Simd4Real rSimd4_logicalResultAnd = setSimd4RealFrom1R(1.26666259765625); // mantissa 0100010001000100
 const Simd4Real rSimd4_logicalResultOr = setSimd4RealFrom1R(1.8666534423828125); // mantissa 1101110111011101
-#            endif                                 // GMX_DOUBLE
-#        endif                                     // GMX_SIMD_HAVE_LOGICAL
+#                endif                             // GMX_DOUBLE
+#            endif                                 // GMX_SIMD_HAVE_LOGICAL
+#        endif                                     // GMX_SIMD4_HAVE_REAL_GLOBAL
 
 ::std::vector<real> simd4Real2Vector(const Simd4Real simd4)
 {
diff --git a/src/gromacs/simd/tests/simd4.h b/src/gromacs/simd/tests/simd4.h
index 6378bf9..2f7f44f 100644
--- a/src/gromacs/simd/tests/simd4.h
+++ b/src/gromacs/simd/tests/simd4.h
@@ -68,6 +68,7 @@ namespace test
 /*! \{ */
 
 #    if GMX_SIMD4_HAVE_REAL
+#        if GMX_SIMD4_HAVE_REAL_GLOBAL
 extern const Simd4Real rSimd4_c0c1c2; //!< c0,c1,c2 repeated
 extern const Simd4Real rSimd4_c3c4c5; //!< c3,c4,c5 repeated
 extern const Simd4Real rSimd4_c6c7c8; //!< c6,c7,c8 repeated
@@ -83,12 +84,12 @@ extern const Simd4Real rSimd4_m3p75;  //!< Negative value that rounds down.
 //! Three large floating-point values whose exponents are >32.
 extern const Simd4Real rSimd4_Exp;
 
-#        if GMX_SIMD_HAVE_LOGICAL
+#            if GMX_SIMD_HAVE_LOGICAL
 extern const Simd4Real rSimd4_logicalA;         //!< Bit pattern to test logical ops
 extern const Simd4Real rSimd4_logicalB;         //!< Bit pattern to test logical ops
 extern const Simd4Real rSimd4_logicalResultOr;  //!< Result or bitwise 'or' of A and B
 extern const Simd4Real rSimd4_logicalResultAnd; //!< Result or bitwise 'and' of A and B
-#        endif                                  // GMX_SIMD_HAVE_LOGICAL
+#            endif                              // GMX_SIMD_HAVE_LOGICAL
 
 extern const Simd4Real rSimd4_Bits1; //!< Pattern F0 repeated to fill single/double.
 extern const Simd4Real rSimd4_Bits2; //!< Pattern CC repeated to fill single/double.
@@ -96,6 +97,55 @@ extern const Simd4Real rSimd4_Bits3; //!< Pattern C0 repeated to fill single/dou
 extern const Simd4Real rSimd4_Bits4; //!< Pattern 0C repeated to fill single/double.
 extern const Simd4Real rSimd4_Bits5; //!< Pattern FC repeated to fill single/double.
 extern const Simd4Real rSimd4_Bits6; //!< Pattern 3C repeated to fill single/double.
+#        else                        // GMX_SIMD4_HAVE_REAL_GLOBAL
+//!< c0,c1,c2 repeated
+#            define rSimd4_c0c1c2 setSimd4RealFrom3R(c0, c1, c2)
+//!< c3,c4,c5 repeated
+#            define rSimd4_c3c4c5 setSimd4RealFrom3R(c3, c4, c5)
+//!< c6,c7,c8 repeated
+#            define rSimd4_c6c7c8 setSimd4RealFrom3R(c6, c7, c8)
+//!< c3,c0,c4 repeated
+#            define rSimd4_c3c0c4 setSimd4RealFrom3R(c3, c0, c4)
+//!< c4,c6,c8 repeated
+#            define rSimd4_c4c6c8 setSimd4RealFrom3R(c4, c6, c8)
+//!< c7,c2,c3 repeated
+#            define rSimd4_c7c2c3 setSimd4RealFrom3R(c7, c2, c3)
+//!< -c0,-c1,-c2 repeated
+#            define rSimd4_m0m1m2 setSimd4RealFrom3R(-c0, -c1, -c2)
+//!< -c3,-c0,-c4 repeated
+#            define rSimd4_m3m0m4 setSimd4RealFrom3R(-c3, -c0, -c4)
+//!< Value that rounds down.
+#            define rSimd4_2p25 setSimd4RealFrom1R(2.25)
+//!< Value that rounds up.
+#            define rSimd4_3p75 setSimd4RealFrom1R(3.75)
+//!< Negative value that rounds up.
+#            define rSimd4_m2p25 setSimd4RealFrom1R(-2.25)
+//!< Negative value that rounds down.
+#            define rSimd4_m3p75 setSimd4RealFrom1R(-3.75)
+//! Three large floating-point values whose exponents are >32.
+
+#            if GMX_SIMD_HAVE_LOGICAL
+//!< Result or bitwise 'and' of A and B
+#                if GMX_DOUBLE
+#                    define rSimd4_logicalA setSimd4RealFrom1R(1.3333333332557231188)
+//!< Bit pattern to test logical ops
+#                    define rSimd4_logicalB setSimd4RealFrom1R(1.7999999998137354851)
+//!< Result or bitwise 'or' of A and B
+#                    define rSimd4_logicalResultAnd setSimd4RealFrom1R(1.266666666604578495)
+//!< Bit pattern to test logical ops
+#                    define rSimd4_logicalResultOr setSimd4RealFrom1R(1.8666666664648801088)
+#                else // GMX_DOUBLE
+//!< Bit pattern to test logical ops
+#                    define rSimd4_logicalA setSimd4RealFrom1R(1.3333282470703125)
+//!< Bit pattern to test logical ops
+define rSimd4_logicalB setSimd4RealFrom1R(1.79998779296875)
+//!< Result or bitwise 'or' of A and B
+#                    define rSimd4_logicalResultAnd setSimd4RealFrom1R(1.26666259765625)
+//!< Bit pattern to test logical ops
+#                    define rSimd4_logicalResultOr setSimd4RealFrom1R(1.8666534423828125)
+#                endif // GMX_DOUBLE
+#            endif     // GMX_SIMD_HAVE_LOGICAL
+#        endif         // GMX_SIMD4_HAVE_REAL_GLOBAL
 
 /*! \internal
  * \brief
-- 
1.8.3.1

From 1cdf6b7159ba31e21661971fabf86fde91c009c9 Mon Sep 17 00:00:00 2001
From: Gilles Gouaillardet <gilles@rist.or.jp>
Date: Mon, 25 May 2020 17:52:49 +0900
Subject: [PATCH 09/32] SVE_FULL_LENGTH on by default

(cherry picked from commit 423d54a534c68d04eeedc9b360c28bb576fb04f7)
---
 cmake/gmxManageSimd.cmake | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/cmake/gmxManageSimd.cmake b/cmake/gmxManageSimd.cmake
index cacb557..46b75f2 100644
--- a/cmake/gmxManageSimd.cmake
+++ b/cmake/gmxManageSimd.cmake
@@ -283,7 +283,7 @@ elseif(GMX_SIMD_ACTIVE STREQUAL "ARM_SVE")
             add_definitions(-DGMX_SIMD_ARM_SVE_GNU=0)
         endif()
 
-        option(GMX_SIMD_ARM_SVE_FULL_LENGTH "Always use full length vectors" OFF)
+        option(GMX_SIMD_ARM_SVE_FULL_LENGTH "Always use full length vectors" ON)
 
         set(GMX_SIMD_${GMX_SIMD_ACTIVE} 1)
         set(SIMD_STATUS_MESSAGE "Enabling ARM (AArch64) SVE extensions without special flags.")
-- 
1.8.3.1

